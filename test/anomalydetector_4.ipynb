{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "import glob\n",
    "\n",
    "from csv import (writer, DictWriter)\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from drain3 import TemplateMiner\n",
    "from drain3.template_miner_config import TemplateMinerConfig\n",
    "\n",
    "from spellpy import spell\n",
    "from fastai.text.all import Numericalize\n",
    "\n",
    "import fasttext\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import (confusion_matrix, precision_score, recall_score, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = os.getcwd()\n",
    "\n",
    "data_dir = 'data'\n",
    "log_file_name = 'bgl_2k.log'\n",
    "\n",
    "config_dir = 'config'\n",
    "\n",
    "input_dir = 'input'\n",
    "spell_output_dir = 'output'\n",
    "\n",
    "spell_input_dir = 'input/spell'\n",
    "spell_output_dir = 'output/spell'\n",
    "\n",
    "drain_input_dir = 'input/drain'\n",
    "drain_output_dir = 'output/drain'\n",
    "\n",
    "WINDOW_SIZE = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert BGL.log file to CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 14 fields in line 8, saw 16\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pd\u001b[39m.\u001b[39;49mread_csv(path\u001b[39m.\u001b[39;49mabspath(path\u001b[39m.\u001b[39;49mjoin(project_root, \u001b[39m'\u001b[39;49m\u001b[39m../\u001b[39;49m\u001b[39m'\u001b[39;49m, data_dir, log_file_name)), sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/home/dsdev/anaconda3/envs/ms-ds13/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/dsdev/anaconda3/envs/ms-ds13/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/dsdev/anaconda3/envs/ms-ds13/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/home/dsdev/anaconda3/envs/ms-ds13/lib/python3.9/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    610\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 611\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m/home/dsdev/anaconda3/envs/ms-ds13/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1771\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1772\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1773\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m     (\n\u001b[1;32m   1775\u001b[0m         index,\n\u001b[1;32m   1776\u001b[0m         columns,\n\u001b[1;32m   1777\u001b[0m         col_dict,\n\u001b[0;32m-> 1778\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1779\u001b[0m         nrows\n\u001b[1;32m   1780\u001b[0m     )\n\u001b[1;32m   1781\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/home/dsdev/anaconda3/envs/ms-ds13/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 230\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[1;32m    231\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    232\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m/home/dsdev/anaconda3/envs/ms-ds13/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/home/dsdev/anaconda3/envs/ms-ds13/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/home/dsdev/anaconda3/envs/ms-ds13/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/home/dsdev/anaconda3/envs/ms-ds13/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 14 fields in line 8, saw 16\n"
     ]
    }
   ],
   "source": [
    "pd.read_csv(path.abspath(path.join(project_root, '../', data_dir, log_file_name)), sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 14 fields in line 8, saw 16\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     os\u001b[39m.\u001b[39mremove(log_csv_file)\n\u001b[1;32m      7\u001b[0m log_file \u001b[39m=\u001b[39m path\u001b[39m.\u001b[39mabspath(path\u001b[39m.\u001b[39mjoin(project_root, \u001b[39m'\u001b[39m\u001b[39m../\u001b[39m\u001b[39m'\u001b[39m, data_dir, log_file_name))\n\u001b[0;32m----> 8\u001b[0m pd\u001b[39m.\u001b[39;49mread_csv(path\u001b[39m.\u001b[39;49mjoin(project_root, \u001b[39m'\u001b[39;49m\u001b[39m../\u001b[39;49m\u001b[39m'\u001b[39;49m, data_dir, log_file_name), sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      9\u001b[0m logs \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(log_file, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(log_csv_file, \u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m log_csv_file_obj:\n",
      "File \u001b[0;32m/home/dsdev/anaconda3/envs/ms-ds13/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/dsdev/anaconda3/envs/ms-ds13/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/dsdev/anaconda3/envs/ms-ds13/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/home/dsdev/anaconda3/envs/ms-ds13/lib/python3.9/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    610\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 611\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m/home/dsdev/anaconda3/envs/ms-ds13/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1771\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1772\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1773\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m     (\n\u001b[1;32m   1775\u001b[0m         index,\n\u001b[1;32m   1776\u001b[0m         columns,\n\u001b[1;32m   1777\u001b[0m         col_dict,\n\u001b[0;32m-> 1778\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1779\u001b[0m         nrows\n\u001b[1;32m   1780\u001b[0m     )\n\u001b[1;32m   1781\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/home/dsdev/anaconda3/envs/ms-ds13/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 230\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[1;32m    231\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    232\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m/home/dsdev/anaconda3/envs/ms-ds13/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/home/dsdev/anaconda3/envs/ms-ds13/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/home/dsdev/anaconda3/envs/ms-ds13/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/home/dsdev/anaconda3/envs/ms-ds13/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 14 fields in line 8, saw 16\n"
     ]
    }
   ],
   "source": [
    "log_csv_file_name = 'bgl_2k.csv'\n",
    "log_csv_file = log_file = path.abspath(path.join(project_root, input_dir, log_csv_file_name))\n",
    "\n",
    "if os.path.exists(log_csv_file):\n",
    "    os.remove(log_csv_file)\n",
    "\n",
    "log_file = path.abspath(path.join(project_root, '../', data_dir, log_file_name))\n",
    "logs = open(log_file, 'r')\n",
    "\n",
    "with open(log_csv_file, 'a') as log_csv_file_obj:\n",
    "    log_csv_writer_obj = writer(log_csv_file_obj)\n",
    "    for line in logs:\n",
    "        split_data = line.rstrip('\\n').split(' ')\n",
    "        split_data[9] = ' '.join(split_data[9:])\n",
    "        log_csv_writer_obj.writerow(split_data[0:10])\n",
    "    log_csv_file_obj.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anomaly Type</th>\n",
       "      <th>Timestamp (ms)</th>\n",
       "      <th>Date</th>\n",
       "      <th>Node</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Node Repeat</th>\n",
       "      <th>Message Type</th>\n",
       "      <th>Component</th>\n",
       "      <th>Level</th>\n",
       "      <th>Content</th>\n",
       "      <th>Anomaly Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-</td>\n",
       "      <td>1117838570</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03-15.42.50.675872</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>1117838573</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03-15.42.53.276129</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>1117838976</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03-15.49.36.156884</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-</td>\n",
       "      <td>1117838978</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03-15.49.38.026704</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-</td>\n",
       "      <td>1117842440</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R23-M0-NE-C:J05-U01</td>\n",
       "      <td>2005-06-03-16.47.20.730545</td>\n",
       "      <td>R23-M0-NE-C:J05-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>63543 double-hummer alignment exceptions</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-</td>\n",
       "      <td>1117842974</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R24-M0-N1-C:J13-U11</td>\n",
       "      <td>2005-06-03-16.56.14.254137</td>\n",
       "      <td>R24-M0-N1-C:J13-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>162 double-hummer alignment exceptions</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-</td>\n",
       "      <td>1117843015</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R21-M1-N6-C:J08-U11</td>\n",
       "      <td>2005-06-03-16.56.55.309974</td>\n",
       "      <td>R21-M1-N6-C:J08-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>141 double-hummer alignment exceptions</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-</td>\n",
       "      <td>1117848119</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R16-M1-N2-C:J17-U01</td>\n",
       "      <td>2005-06-03-18.21.59.871925</td>\n",
       "      <td>R16-M1-N2-C:J17-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>CE sym 2, at 0x0b85eee0, mask 0x05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>APPREAD</td>\n",
       "      <td>1117869872</td>\n",
       "      <td>2005.06.04</td>\n",
       "      <td>R04-M1-N4-I:J18-U11</td>\n",
       "      <td>2005-06-04-00.24.32.432192</td>\n",
       "      <td>R04-M1-N4-I:J18-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>APP</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33569</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>APPREAD</td>\n",
       "      <td>1117869876</td>\n",
       "      <td>2005.06.04</td>\n",
       "      <td>R27-M1-N4-I:J18-U01</td>\n",
       "      <td>2005-06-04-00.24.36.222560</td>\n",
       "      <td>R27-M1-N4-I:J18-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>APP</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-</td>\n",
       "      <td>1117942120</td>\n",
       "      <td>2005.06.04</td>\n",
       "      <td>R30-M0-N7-C:J08-U01</td>\n",
       "      <td>2005-06-04-20.28.40.767551</td>\n",
       "      <td>R30-M0-N7-C:J08-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>CE sym 20, at 0x1438f9e0, mask 0x40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-</td>\n",
       "      <td>1117955341</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R25-M0-N7-C:J02-U01</td>\n",
       "      <td>2005-06-05-00.09.01.903373</td>\n",
       "      <td>R25-M0-N7-C:J02-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.2275</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-</td>\n",
       "      <td>1117955392</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R24-M1-N8-C:J09-U11</td>\n",
       "      <td>2005-06-05-00.09.52.516674</td>\n",
       "      <td>R24-M1-N8-C:J09-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.862</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-</td>\n",
       "      <td>1117956980</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R24-M1-NB-C:J15-U11</td>\n",
       "      <td>2005-06-05-00.36.20.945796</td>\n",
       "      <td>R24-M1-NB-C:J15-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.728</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-</td>\n",
       "      <td>1117957045</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R20-M1-N8-C:J04-U01</td>\n",
       "      <td>2005-06-05-00.37.25.012681</td>\n",
       "      <td>R20-M1-N8-C:J04-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-</td>\n",
       "      <td>1117959501</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R24-M0-NE-C:J14-U11</td>\n",
       "      <td>2005-06-05-01.18.21.778604</td>\n",
       "      <td>R24-M0-NE-C:J14-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.3276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-</td>\n",
       "      <td>1117959513</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R21-M1-N2-C:J11-U01</td>\n",
       "      <td>2005-06-05-01.18.33.830595</td>\n",
       "      <td>R21-M1-N2-C:J11-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.1717</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-</td>\n",
       "      <td>1117959563</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R24-M0-N8-C:J04-U11</td>\n",
       "      <td>2005-06-05-01.19.23.822135</td>\n",
       "      <td>R24-M0-N8-C:J04-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.3919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-</td>\n",
       "      <td>1117973759</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R31-M0-NE-C:J05-U11</td>\n",
       "      <td>2005-06-05-05.15.59.416717</td>\n",
       "      <td>R31-M0-NE-C:J05-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.2079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-</td>\n",
       "      <td>1117973786</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R36-M0-NA-C:J06-U01</td>\n",
       "      <td>2005-06-05-05.16.26.686603</td>\n",
       "      <td>R36-M0-NA-C:J06-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.1414</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Anomaly Type  Timestamp (ms)        Date                 Node  \\\n",
       "0             -      1117838570  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "1             -      1117838573  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "2             -      1117838976  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "3             -      1117838978  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "4             -      1117842440  2005.06.03  R23-M0-NE-C:J05-U01   \n",
       "5             -      1117842974  2005.06.03  R24-M0-N1-C:J13-U11   \n",
       "6             -      1117843015  2005.06.03  R21-M1-N6-C:J08-U11   \n",
       "7             -      1117848119  2005.06.03  R16-M1-N2-C:J17-U01   \n",
       "8       APPREAD      1117869872  2005.06.04  R04-M1-N4-I:J18-U11   \n",
       "9       APPREAD      1117869876  2005.06.04  R27-M1-N4-I:J18-U01   \n",
       "10            -      1117942120  2005.06.04  R30-M0-N7-C:J08-U01   \n",
       "11            -      1117955341  2005.06.05  R25-M0-N7-C:J02-U01   \n",
       "12            -      1117955392  2005.06.05  R24-M1-N8-C:J09-U11   \n",
       "13            -      1117956980  2005.06.05  R24-M1-NB-C:J15-U11   \n",
       "14            -      1117957045  2005.06.05  R20-M1-N8-C:J04-U01   \n",
       "15            -      1117959501  2005.06.05  R24-M0-NE-C:J14-U11   \n",
       "16            -      1117959513  2005.06.05  R21-M1-N2-C:J11-U01   \n",
       "17            -      1117959563  2005.06.05  R24-M0-N8-C:J04-U11   \n",
       "18            -      1117973759  2005.06.05  R31-M0-NE-C:J05-U11   \n",
       "19            -      1117973786  2005.06.05  R36-M0-NA-C:J06-U01   \n",
       "\n",
       "                     Timestamp          Node Repeat Message Type Component  \\\n",
       "0   2005-06-03-15.42.50.675872  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "1   2005-06-03-15.42.53.276129  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "2   2005-06-03-15.49.36.156884  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "3   2005-06-03-15.49.38.026704  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "4   2005-06-03-16.47.20.730545  R23-M0-NE-C:J05-U01          RAS    KERNEL   \n",
       "5   2005-06-03-16.56.14.254137  R24-M0-N1-C:J13-U11          RAS    KERNEL   \n",
       "6   2005-06-03-16.56.55.309974  R21-M1-N6-C:J08-U11          RAS    KERNEL   \n",
       "7   2005-06-03-18.21.59.871925  R16-M1-N2-C:J17-U01          RAS    KERNEL   \n",
       "8   2005-06-04-00.24.32.432192  R04-M1-N4-I:J18-U11          RAS       APP   \n",
       "9   2005-06-04-00.24.36.222560  R27-M1-N4-I:J18-U01          RAS       APP   \n",
       "10  2005-06-04-20.28.40.767551  R30-M0-N7-C:J08-U01          RAS    KERNEL   \n",
       "11  2005-06-05-00.09.01.903373  R25-M0-N7-C:J02-U01          RAS    KERNEL   \n",
       "12  2005-06-05-00.09.52.516674  R24-M1-N8-C:J09-U11          RAS    KERNEL   \n",
       "13  2005-06-05-00.36.20.945796  R24-M1-NB-C:J15-U11          RAS    KERNEL   \n",
       "14  2005-06-05-00.37.25.012681  R20-M1-N8-C:J04-U01          RAS    KERNEL   \n",
       "15  2005-06-05-01.18.21.778604  R24-M0-NE-C:J14-U11          RAS    KERNEL   \n",
       "16  2005-06-05-01.18.33.830595  R21-M1-N2-C:J11-U01          RAS    KERNEL   \n",
       "17  2005-06-05-01.19.23.822135  R24-M0-N8-C:J04-U11          RAS    KERNEL   \n",
       "18  2005-06-05-05.15.59.416717  R31-M0-NE-C:J05-U11          RAS    KERNEL   \n",
       "19  2005-06-05-05.16.26.686603  R36-M0-NA-C:J06-U01          RAS    KERNEL   \n",
       "\n",
       "    Level  \\\n",
       "0    INFO   \n",
       "1    INFO   \n",
       "2    INFO   \n",
       "3    INFO   \n",
       "4    INFO   \n",
       "5    INFO   \n",
       "6    INFO   \n",
       "7    INFO   \n",
       "8   FATAL   \n",
       "9   FATAL   \n",
       "10   INFO   \n",
       "11   INFO   \n",
       "12   INFO   \n",
       "13   INFO   \n",
       "14   INFO   \n",
       "15   INFO   \n",
       "16   INFO   \n",
       "17   INFO   \n",
       "18   INFO   \n",
       "19   INFO   \n",
       "\n",
       "                                                                                           Content  \\\n",
       "0                                                         instruction cache parity error corrected   \n",
       "1                                                         instruction cache parity error corrected   \n",
       "2                                                         instruction cache parity error corrected   \n",
       "3                                                         instruction cache parity error corrected   \n",
       "4                                                         63543 double-hummer alignment exceptions   \n",
       "5                                                           162 double-hummer alignment exceptions   \n",
       "6                                                           141 double-hummer alignment exceptions   \n",
       "7                                                               CE sym 2, at 0x0b85eee0, mask 0x05   \n",
       "8   ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33569   \n",
       "9   ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33370   \n",
       "10                                                             CE sym 20, at 0x1438f9e0, mask 0x40   \n",
       "11                                                                            generating core.2275   \n",
       "12                                                                             generating core.862   \n",
       "13                                                                             generating core.728   \n",
       "14                                                                             generating core.775   \n",
       "15                                                                            generating core.3276   \n",
       "16                                                                            generating core.1717   \n",
       "17                                                                            generating core.3919   \n",
       "18                                                                            generating core.2079   \n",
       "19                                                                            generating core.1414   \n",
       "\n",
       "    Anomaly Label  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "5               0  \n",
       "6               0  \n",
       "7               0  \n",
       "8               1  \n",
       "9               1  \n",
       "10              0  \n",
       "11              0  \n",
       "12              0  \n",
       "13              0  \n",
       "14              0  \n",
       "15              0  \n",
       "16              0  \n",
       "17              0  \n",
       "18              0  \n",
       "19              0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = pd.read_csv(log_csv_file, names=['Anomaly Type', 'Timestamp (ms)', 'Date', 'Node', 'Timestamp', 'Node Repeat', 'Message Type', 'Component', 'Level', 'Content'])\n",
    "original_df['Anomaly Label'] = np.where(original_df['Anomaly Type'] == '-', 0, 1)\n",
    "original_df.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anomaly Label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>63543 double-hummer alignment exceptions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>162 double-hummer alignment exceptions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>141 double-hummer alignment exceptions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>CE sym 2, at 0x0b85eee0, mask 0x05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>CE sym 20, at 0x1438f9e0, mask 0x40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.2275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.3276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.1717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.3919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.2079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.1414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Anomaly Label  \\\n",
       "0               0   \n",
       "1               0   \n",
       "2               0   \n",
       "3               0   \n",
       "4               0   \n",
       "5               0   \n",
       "6               0   \n",
       "7               0   \n",
       "8               1   \n",
       "9               1   \n",
       "10              0   \n",
       "11              0   \n",
       "12              0   \n",
       "13              0   \n",
       "14              0   \n",
       "15              0   \n",
       "16              0   \n",
       "17              0   \n",
       "18              0   \n",
       "19              0   \n",
       "\n",
       "                                                                                           Content  \n",
       "0                                                         instruction cache parity error corrected  \n",
       "1                                                         instruction cache parity error corrected  \n",
       "2                                                         instruction cache parity error corrected  \n",
       "3                                                         instruction cache parity error corrected  \n",
       "4                                                         63543 double-hummer alignment exceptions  \n",
       "5                                                           162 double-hummer alignment exceptions  \n",
       "6                                                           141 double-hummer alignment exceptions  \n",
       "7                                                               CE sym 2, at 0x0b85eee0, mask 0x05  \n",
       "8   ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33569  \n",
       "9   ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33370  \n",
       "10                                                             CE sym 20, at 0x1438f9e0, mask 0x40  \n",
       "11                                                                            generating core.2275  \n",
       "12                                                                             generating core.862  \n",
       "13                                                                             generating core.728  \n",
       "14                                                                             generating core.775  \n",
       "15                                                                            generating core.3276  \n",
       "16                                                                            generating core.1717  \n",
       "17                                                                            generating core.3919  \n",
       "18                                                                            generating core.2079  \n",
       "19                                                                            generating core.1414  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = original_df[['Anomaly Label', 'Content']]\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Log Sequences and Labels for Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = math.floor(df['Content'].index.size/WINDOW_SIZE)\n",
    "r = math.floor(df['Content'].index.size%WINDOW_SIZE)\n",
    "\n",
    "if r != 0:\n",
    "    log_seqs = np.array(np.split(np.array(df['Content'])[:-r], n))\n",
    "else:\n",
    "    log_seqs = np.array(np.split(np.array(df['Content']), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if r != 0:\n",
    "    log_seq_idx = np.array(np.split(df.index.to_numpy()[:-r], n))\n",
    "else:\n",
    "    log_seq_idx = np.array(np.split(df.index.to_numpy(), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_seq_anomaly_labels = np.empty([n], dtype=int)\n",
    "i = 0\n",
    "for seq in log_seq_idx:\n",
    "    if np.sum(df.loc[seq]['Anomaly Label'].values) > 0:\n",
    "        log_seq_anomaly_labels[i] = 1\n",
    "    else:\n",
    "        log_seq_anomaly_labels[i] = 0\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Parsing & Numericalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drain Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(drain_input_dir + '/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "files = glob.glob(drain_output_dir + '/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "drain_config_file = path.abspath(path.join(project_root, config_dir, 'drain3.ini'))\n",
    "\n",
    "main_structured_csv_filename = 'BGL_main_structured.csv'\n",
    "drain_main_structured_csv_file = path.abspath(path.join(project_root, drain_output_dir, main_structured_csv_filename))\n",
    "\n",
    "templates_csv_filename = 'BGL_main_templates.csv'\n",
    "drain_templates_csv_file = path.abspath(path.join(project_root, drain_output_dir, templates_csv_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrainParser(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        config = TemplateMinerConfig()\n",
    "        config.load(drain_config_file)\n",
    "\n",
    "        self.template_miner = TemplateMiner(config=config)\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, log_seqs, y = None):\n",
    "        log_seqs_list = log_seqs.reshape([-1]).tolist()\n",
    "        self.parsed = []\n",
    "\n",
    "        for line in log_seqs_list:\n",
    "            self.parsed.append(self.template_miner.add_log_message(line))\n",
    "\n",
    "        # Uncomment during debug to view the parser output\n",
    "        # self.write_output_to_csv()\n",
    "\n",
    "        template_seq = [str(x['cluster_id']-1) for x in self.parsed]\n",
    "        n = math.floor(len(template_seq)/WINDOW_SIZE)\n",
    "        template_seqs = np.array(np.split(np.array(template_seq), n))\n",
    "\n",
    "        return template_seqs\n",
    "    \n",
    "    def cluster_template_to_tuple(self, cluster):\n",
    "        return (cluster.cluster_id, cluster.get_template(), cluster.size,)\n",
    "\n",
    "    def write_output_to_csv(self):\n",
    "        with open(drain_main_structured_csv_file, 'w') as drain_main_structured_csv_file_obj:\n",
    "            main_structured_csv_filewriter = DictWriter(drain_main_structured_csv_file_obj, fieldnames=['template_mined', 'cluster_id', 'change_type', 'cluster_size', 'cluster_count'])\n",
    "            main_structured_csv_filewriter.writeheader()\n",
    "            for line in self.parsed:\n",
    "                main_structured_csv_filewriter.writerow(line)\n",
    "            drain_main_structured_csv_file_obj.close\n",
    "            \n",
    "        clusters = self.template_miner.drain.clusters\n",
    "\n",
    "        with open(drain_templates_csv_file, 'a') as drain_templates_csv_file_obj:\n",
    "            drain_templates_csv_filewriter = writer(drain_templates_csv_file_obj)\n",
    "            drain_templates_csv_filewriter.writerow(header for header in ['cluster_id', 'template', 'size'])\n",
    "            for line in clusters:\n",
    "                drain_templates_csv_filewriter.writerow(self.cluster_template_to_tuple(line))\n",
    "            drain_templates_csv_file_obj.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spell Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_content_csv_file_name = 'bgl_2k_content.csv'\n",
    "log_content_csv_file = log_file = path.abspath(path.join(project_root, spell_input_dir, log_content_csv_file_name))\n",
    "\n",
    "main_structured_csv_filename = 'BGL_main_structured.csv'\n",
    "spell_main_structured_csv_file = path.abspath(path.join(project_root, spell_output_dir, main_structured_csv_filename))\n",
    "\n",
    "templates_csv_filename = 'BGL_main_templates.csv'\n",
    "spell_templates_csv_file = path.abspath(path.join(project_root, spell_output_dir, templates_csv_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpellParser(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        log_format = '<Content>'\n",
    "        tau = 0.5\n",
    "\n",
    "        self.parser = spell.LogParser(indir=spell_input_dir, outdir=spell_output_dir,\n",
    "                             log_format=log_format, tau=tau, logmain='BGL')\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, log_seqs, y = None):\n",
    "        log_seqs_list = log_seqs.reshape([-1]).tolist()\n",
    "\n",
    "        ldf = pd.DataFrame(log_seqs_list, columns=['Content'])\n",
    "        ldf.to_csv(log_content_csv_file, index=False, header=False)\n",
    "\n",
    "        self.parser.parse(log_content_csv_file_name)\n",
    "\n",
    "        nums = self.numericalize()\n",
    "        n = math.floor(len(nums)/WINDOW_SIZE)\n",
    "        nums = np.array(np.split(nums, n))\n",
    "        \n",
    "        # Comment during debug to view parser output\n",
    "        # self.cleanup_files()\n",
    "        \n",
    "        return nums\n",
    "\n",
    "    def numericalize(self):\n",
    "        output_df = pd.read_csv(spell_main_structured_csv_file)\n",
    "        template_df = pd.read_csv(spell_templates_csv_file)\n",
    "\n",
    "        vocab = template_df['EventId']\n",
    "        text = output_df['EventId']\n",
    "\n",
    "        print(text)\n",
    "        num = Numericalize(vocab.to_numpy(), min_freq=1)\n",
    "        num.setup()\n",
    "        nums = np.array(num(text.to_numpy()))\n",
    "\n",
    "        return nums\n",
    "\n",
    "    def cleanup_files(self):\n",
    "        files = glob.glob(spell_input_dir + '/*')\n",
    "        for f in files:\n",
    "            os.remove(f)\n",
    "\n",
    "        files = glob.glob(spell_output_dir + '/*')\n",
    "        for f in files:\n",
    "            os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbedding(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.NUMBER_OF_DIMENSIONS = 100\n",
    "\n",
    "    def fit(self, template_seqs, y = None):\n",
    "        template_seqs_filename = 'bgl_train_seqs.txt'\n",
    "        template_seqs_file = path.abspath(path.join(project_root, spell_output_dir, template_seqs_filename))\n",
    "        np.savetxt(template_seqs_file, template_seqs)\n",
    "        self.fasttext_model = fasttext.train_unsupervised(template_seqs_file, model='cbow', minCount=1, dim=self.NUMBER_OF_DIMENSIONS)\n",
    "        \n",
    "        # Comment during debug to view embedding input\n",
    "        os.remove(template_seqs_file)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, template_seqs, y = None):\n",
    "        template_seqs_ = template_seqs.copy()\n",
    "        template_seqs_ = np.apply_along_axis(self.average_embeddings, 1, template_seqs)\n",
    "\n",
    "        return template_seqs_\n",
    "\n",
    "    def average_embeddings(self, num_lse_vector):\n",
    "        w2v_vector = [self.fasttext_model.get_word_vector(word) for word in np.vectorize(str)(num_lse_vector)]\n",
    "        return np.average(w2v_vector, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbedding_2(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.NUMBER_OF_DIMENSIONS = 100\n",
    "\n",
    "    def fit(self, template_seqs, y = None):\n",
    "        template_seqs_filename = 'bgl_train_seqs.txt'\n",
    "        template_seqs_file = path.abspath(path.join(project_root, spell_output_dir, template_seqs_filename))\n",
    "        np.savetxt(template_seqs_file, template_seqs.astype(int), fmt='%i')\n",
    "        self.fasttext_model = fasttext.train_unsupervised(template_seqs_file, model='cbow', minCount=1, dim=self.NUMBER_OF_DIMENSIONS)\n",
    "        \n",
    "        # Comment during debug to view embedding input\n",
    "        os.remove(template_seqs_file)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, template_seqs, y = None):\n",
    "        template_seqs_ = template_seqs.copy()\n",
    "        template_seqs_ = np.apply_along_axis(self.average_embeddings, 1, template_seqs)\n",
    "\n",
    "        return template_seqs_\n",
    "\n",
    "    def average_embeddings(self, num_lse_vector):\n",
    "        s2v_vector = self.fasttext_model.get_sentence_vector(' '.join(np.vectorize(str)(num_lse_vector)))\n",
    "        return s2v_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
    "for train, test in cv.split(log_seqs, log_seq_anomaly_labels):\n",
    "    print(train.shape, test.shape)\n",
    "\n",
    "drain_pipe = Pipeline(steps=[('parsing', DrainParser()), ('word_embedding', WordEmbedding()), ('gnb', GaussianNB())])\n",
    "drain_pred_log_seq_anomaly_labels = drain_pipe.fit(log_seqs[train], log_seq_anomaly_labels[train]).predict(log_seqs[test])\n",
    "\n",
    "spell_pipe = Pipeline(steps=[('parsing', SpellParser()), ('word_embedding', WordEmbedding()), ('gnb', GaussianNB())])\n",
    "spell_pred_log_seq_anomaly_labels = spell_pipe.fit(log_seqs[train], log_seq_anomaly_labels[train]).predict(log_seqs[test])\n",
    "\n",
    "print(log_seq_anomaly_labels[test])\n",
    "print(drain_pred_log_seq_anomaly_labels)\n",
    "print(spell_pred_log_seq_anomaly_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.read_csv(spell_main_structured_csv_file)\n",
    "nums = output_df['EventId'].to_numpy()\n",
    "n = math.floor(len(nums)/WINDOW_SIZE)\n",
    "nums = np.array(np.split(nums, n))\n",
    "\n",
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n"
     ]
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
    "for train, test in cv.split(log_seqs, log_seq_anomaly_labels):\n",
    "    print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-22 18:14:58,308][INFO]: Starting Drain3 template miner\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(spell_input_dir + '/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "files = glob.glob(spell_output_dir + '/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "test_log_seqs = log_seqs[train]\n",
    "test_log_seq_anomaly_labels = log_seq_anomaly_labels[train]\n",
    "\n",
    "drain_parser = DrainParser()\n",
    "drain_parser.fit(test_log_seqs, test_log_seq_anomaly_labels)\n",
    "drain_template_seqs_output = drain_parser.transform(test_log_seqs, test_log_seq_anomaly_labels)\n",
    "for templ_seq in drain_template_seqs_output:\n",
    "    print(type(templ_seq[0]))\n",
    "\n",
    "# spell_parser = SpellParser()\n",
    "# spell_parser.fit(test_log_seqs, test_log_seq_anomaly_labels)\n",
    "# spell_template_seqs_output = spell_parser.transform(test_log_seqs, test_log_seq_anomaly_labels)\n",
    "# for templ_seq in spell_template_seqs_output:\n",
    "#     print(templ_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for templ_seq in drain_template_seqs_output:\n",
    "    print(type(str(templ_seq[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.str_"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_seqs_filename = 'bgl_train_seqs.txt'\n",
    "template_seqs_file = path.abspath(path.join(project_root, spell_output_dir, template_seqs_filename))\n",
    "np.savetxt(template_seqs_file, drain_template_seqs_output,fmt='%s')\n",
    "\n",
    "type(drain_template_seqs_output[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drain_embedding = WordEmbedding()\n",
    "drain_embedding.fit(drain_template_seqs_output, log_seq_anomaly_labels[train])\n",
    "drain_word_vector_avg = drain_embedding.transform(drain_template_seqs_output, log_seq_anomaly_labels[train])\n",
    "for wv_avg in drain_word_vector_avg:\n",
    "    print(wv_avg)\n",
    "\n",
    "print('*****************************************************************************************************')\n",
    "\n",
    "# spell_embedding = WordEmbedding()\n",
    "# spell_embedding.fit(spell_template_seqs_output, log_seq_anomaly_labels[train])\n",
    "# spell_word_vector_avg = spell_embedding.transform(spell_template_seqs_output, log_seq_anomaly_labels[train])\n",
    "\n",
    "# for wv_avg in spell_word_vector_avg:\n",
    "#     print(wv_avg)\n",
    "\n",
    "# spell_embedding = WordEmbedding_2()\n",
    "# spell_embedding.fit(spell_template_seqs_output, log_seq_anomaly_labels[train])\n",
    "# spell_word_vector_avg = spell_embedding.transform(spell_template_seqs_output, log_seq_anomaly_labels[train])\n",
    "\n",
    "# for wv_avg in spell_word_vector_avg:\n",
    "#     print(wv_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spell_word_vector_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastai_numericalize():\n",
    "    output_df = pd.read_csv(spell_main_structured_csv_file)\n",
    "    template_df = pd.read_csv(spell_templates_csv_file)\n",
    "\n",
    "    vocab = template_df['EventId']\n",
    "    text = output_df['EventId']\n",
    "\n",
    "    num = Numericalize(vocab.to_numpy(), min_freq=1)\n",
    "    num.setup()\n",
    "    nums = np.array(num(text.to_numpy()))\n",
    "\n",
    "    return nums\n",
    "\n",
    "len(fastai_numericalize())/WINDOW_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_numericalize():\n",
    "    output_df = pd.read_csv(spell_main_structured_csv_file)\n",
    "    template_df = pd.read_csv(spell_templates_csv_file)\n",
    "\n",
    "    vocab = template_df['EventId']\n",
    "    text = output_df['EventId']\n",
    "\n",
    "    print(vocab)\n",
    "    print(text)\n",
    "    nums = []\n",
    "\n",
    "    return nums\n",
    "\n",
    "len(custom_numericalize())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7d5d95ec871826f4c96f39204edc263930b1065d3d6b0d23c0891d0cf865f41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
