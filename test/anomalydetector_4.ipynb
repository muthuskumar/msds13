{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "import glob\n",
    "\n",
    "from csv import (writer, DictWriter)\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from drain3 import TemplateMiner\n",
    "from drain3.template_miner_config import TemplateMinerConfig\n",
    "\n",
    "from spellpy import spell\n",
    "from fastai.text.all import Numericalize\n",
    "\n",
    "import fasttext\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import (confusion_matrix, precision_score, recall_score, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = os.getcwd()\n",
    "\n",
    "data_dir = 'data'\n",
    "log_file_name = 'bgl_2k.log'\n",
    "\n",
    "config_dir = 'config'\n",
    "\n",
    "input_dir = 'input'\n",
    "spell_output_dir = 'output'\n",
    "\n",
    "spell_input_dir = 'input/spell'\n",
    "spell_output_dir = 'output/spell'\n",
    "\n",
    "drain_input_dir = 'input/drain'\n",
    "drain_output_dir = 'output/drain'\n",
    "\n",
    "WINDOW_SIZE = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert BGL.log file to CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_csv_file_name = 'bgl_2k.csv'\n",
    "log_csv_file = log_file = path.abspath(path.join(project_root, '../', input_dir, log_csv_file_name))\n",
    "\n",
    "if os.path.exists(log_csv_file):\n",
    "    os.remove(log_csv_file)\n",
    "\n",
    "log_file = path.abspath(path.join(project_root, '../', data_dir, log_file_name))\n",
    "logs = open(log_file, 'r')\n",
    "\n",
    "with open(log_csv_file, 'a') as log_csv_file_obj:\n",
    "    log_csv_writer_obj = writer(log_csv_file_obj)\n",
    "    for line in logs:\n",
    "        split_data = line.rstrip('\\n').split(' ')\n",
    "        split_data[9] = ' '.join(split_data[9:])\n",
    "        log_csv_writer_obj.writerow(split_data[0:10])\n",
    "    log_csv_file_obj.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anomaly Type</th>\n",
       "      <th>Timestamp (ms)</th>\n",
       "      <th>Date</th>\n",
       "      <th>Node</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Node Repeat</th>\n",
       "      <th>Message Type</th>\n",
       "      <th>Component</th>\n",
       "      <th>Level</th>\n",
       "      <th>Content</th>\n",
       "      <th>Anomaly Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-</td>\n",
       "      <td>1117838570</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03-15.42.50.675872</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>1117838573</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03-15.42.53.276129</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>1117838976</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03-15.49.36.156884</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-</td>\n",
       "      <td>1117838978</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03-15.49.38.026704</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-</td>\n",
       "      <td>1117842440</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R23-M0-NE-C:J05-U01</td>\n",
       "      <td>2005-06-03-16.47.20.730545</td>\n",
       "      <td>R23-M0-NE-C:J05-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>63543 double-hummer alignment exceptions</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-</td>\n",
       "      <td>1117842974</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R24-M0-N1-C:J13-U11</td>\n",
       "      <td>2005-06-03-16.56.14.254137</td>\n",
       "      <td>R24-M0-N1-C:J13-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>162 double-hummer alignment exceptions</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-</td>\n",
       "      <td>1117843015</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R21-M1-N6-C:J08-U11</td>\n",
       "      <td>2005-06-03-16.56.55.309974</td>\n",
       "      <td>R21-M1-N6-C:J08-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>141 double-hummer alignment exceptions</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-</td>\n",
       "      <td>1117848119</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R16-M1-N2-C:J17-U01</td>\n",
       "      <td>2005-06-03-18.21.59.871925</td>\n",
       "      <td>R16-M1-N2-C:J17-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>CE sym 2, at 0x0b85eee0, mask 0x05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>APPREAD</td>\n",
       "      <td>1117869872</td>\n",
       "      <td>2005.06.04</td>\n",
       "      <td>R04-M1-N4-I:J18-U11</td>\n",
       "      <td>2005-06-04-00.24.32.432192</td>\n",
       "      <td>R04-M1-N4-I:J18-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>APP</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33569</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>APPREAD</td>\n",
       "      <td>1117869876</td>\n",
       "      <td>2005.06.04</td>\n",
       "      <td>R27-M1-N4-I:J18-U01</td>\n",
       "      <td>2005-06-04-00.24.36.222560</td>\n",
       "      <td>R27-M1-N4-I:J18-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>APP</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-</td>\n",
       "      <td>1117942120</td>\n",
       "      <td>2005.06.04</td>\n",
       "      <td>R30-M0-N7-C:J08-U01</td>\n",
       "      <td>2005-06-04-20.28.40.767551</td>\n",
       "      <td>R30-M0-N7-C:J08-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>CE sym 20, at 0x1438f9e0, mask 0x40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-</td>\n",
       "      <td>1117955341</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R25-M0-N7-C:J02-U01</td>\n",
       "      <td>2005-06-05-00.09.01.903373</td>\n",
       "      <td>R25-M0-N7-C:J02-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.2275</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-</td>\n",
       "      <td>1117955392</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R24-M1-N8-C:J09-U11</td>\n",
       "      <td>2005-06-05-00.09.52.516674</td>\n",
       "      <td>R24-M1-N8-C:J09-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.862</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-</td>\n",
       "      <td>1117956980</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R24-M1-NB-C:J15-U11</td>\n",
       "      <td>2005-06-05-00.36.20.945796</td>\n",
       "      <td>R24-M1-NB-C:J15-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.728</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-</td>\n",
       "      <td>1117957045</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R20-M1-N8-C:J04-U01</td>\n",
       "      <td>2005-06-05-00.37.25.012681</td>\n",
       "      <td>R20-M1-N8-C:J04-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-</td>\n",
       "      <td>1117959501</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R24-M0-NE-C:J14-U11</td>\n",
       "      <td>2005-06-05-01.18.21.778604</td>\n",
       "      <td>R24-M0-NE-C:J14-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.3276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-</td>\n",
       "      <td>1117959513</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R21-M1-N2-C:J11-U01</td>\n",
       "      <td>2005-06-05-01.18.33.830595</td>\n",
       "      <td>R21-M1-N2-C:J11-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.1717</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-</td>\n",
       "      <td>1117959563</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R24-M0-N8-C:J04-U11</td>\n",
       "      <td>2005-06-05-01.19.23.822135</td>\n",
       "      <td>R24-M0-N8-C:J04-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.3919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-</td>\n",
       "      <td>1117973759</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R31-M0-NE-C:J05-U11</td>\n",
       "      <td>2005-06-05-05.15.59.416717</td>\n",
       "      <td>R31-M0-NE-C:J05-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.2079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-</td>\n",
       "      <td>1117973786</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R36-M0-NA-C:J06-U01</td>\n",
       "      <td>2005-06-05-05.16.26.686603</td>\n",
       "      <td>R36-M0-NA-C:J06-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.1414</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Anomaly Type  Timestamp (ms)        Date                 Node  \\\n",
       "0             -      1117838570  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "1             -      1117838573  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "2             -      1117838976  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "3             -      1117838978  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "4             -      1117842440  2005.06.03  R23-M0-NE-C:J05-U01   \n",
       "5             -      1117842974  2005.06.03  R24-M0-N1-C:J13-U11   \n",
       "6             -      1117843015  2005.06.03  R21-M1-N6-C:J08-U11   \n",
       "7             -      1117848119  2005.06.03  R16-M1-N2-C:J17-U01   \n",
       "8       APPREAD      1117869872  2005.06.04  R04-M1-N4-I:J18-U11   \n",
       "9       APPREAD      1117869876  2005.06.04  R27-M1-N4-I:J18-U01   \n",
       "10            -      1117942120  2005.06.04  R30-M0-N7-C:J08-U01   \n",
       "11            -      1117955341  2005.06.05  R25-M0-N7-C:J02-U01   \n",
       "12            -      1117955392  2005.06.05  R24-M1-N8-C:J09-U11   \n",
       "13            -      1117956980  2005.06.05  R24-M1-NB-C:J15-U11   \n",
       "14            -      1117957045  2005.06.05  R20-M1-N8-C:J04-U01   \n",
       "15            -      1117959501  2005.06.05  R24-M0-NE-C:J14-U11   \n",
       "16            -      1117959513  2005.06.05  R21-M1-N2-C:J11-U01   \n",
       "17            -      1117959563  2005.06.05  R24-M0-N8-C:J04-U11   \n",
       "18            -      1117973759  2005.06.05  R31-M0-NE-C:J05-U11   \n",
       "19            -      1117973786  2005.06.05  R36-M0-NA-C:J06-U01   \n",
       "\n",
       "                     Timestamp          Node Repeat Message Type Component  \\\n",
       "0   2005-06-03-15.42.50.675872  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "1   2005-06-03-15.42.53.276129  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "2   2005-06-03-15.49.36.156884  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "3   2005-06-03-15.49.38.026704  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "4   2005-06-03-16.47.20.730545  R23-M0-NE-C:J05-U01          RAS    KERNEL   \n",
       "5   2005-06-03-16.56.14.254137  R24-M0-N1-C:J13-U11          RAS    KERNEL   \n",
       "6   2005-06-03-16.56.55.309974  R21-M1-N6-C:J08-U11          RAS    KERNEL   \n",
       "7   2005-06-03-18.21.59.871925  R16-M1-N2-C:J17-U01          RAS    KERNEL   \n",
       "8   2005-06-04-00.24.32.432192  R04-M1-N4-I:J18-U11          RAS       APP   \n",
       "9   2005-06-04-00.24.36.222560  R27-M1-N4-I:J18-U01          RAS       APP   \n",
       "10  2005-06-04-20.28.40.767551  R30-M0-N7-C:J08-U01          RAS    KERNEL   \n",
       "11  2005-06-05-00.09.01.903373  R25-M0-N7-C:J02-U01          RAS    KERNEL   \n",
       "12  2005-06-05-00.09.52.516674  R24-M1-N8-C:J09-U11          RAS    KERNEL   \n",
       "13  2005-06-05-00.36.20.945796  R24-M1-NB-C:J15-U11          RAS    KERNEL   \n",
       "14  2005-06-05-00.37.25.012681  R20-M1-N8-C:J04-U01          RAS    KERNEL   \n",
       "15  2005-06-05-01.18.21.778604  R24-M0-NE-C:J14-U11          RAS    KERNEL   \n",
       "16  2005-06-05-01.18.33.830595  R21-M1-N2-C:J11-U01          RAS    KERNEL   \n",
       "17  2005-06-05-01.19.23.822135  R24-M0-N8-C:J04-U11          RAS    KERNEL   \n",
       "18  2005-06-05-05.15.59.416717  R31-M0-NE-C:J05-U11          RAS    KERNEL   \n",
       "19  2005-06-05-05.16.26.686603  R36-M0-NA-C:J06-U01          RAS    KERNEL   \n",
       "\n",
       "    Level  \\\n",
       "0    INFO   \n",
       "1    INFO   \n",
       "2    INFO   \n",
       "3    INFO   \n",
       "4    INFO   \n",
       "5    INFO   \n",
       "6    INFO   \n",
       "7    INFO   \n",
       "8   FATAL   \n",
       "9   FATAL   \n",
       "10   INFO   \n",
       "11   INFO   \n",
       "12   INFO   \n",
       "13   INFO   \n",
       "14   INFO   \n",
       "15   INFO   \n",
       "16   INFO   \n",
       "17   INFO   \n",
       "18   INFO   \n",
       "19   INFO   \n",
       "\n",
       "                                                                                           Content  \\\n",
       "0                                                         instruction cache parity error corrected   \n",
       "1                                                         instruction cache parity error corrected   \n",
       "2                                                         instruction cache parity error corrected   \n",
       "3                                                         instruction cache parity error corrected   \n",
       "4                                                         63543 double-hummer alignment exceptions   \n",
       "5                                                           162 double-hummer alignment exceptions   \n",
       "6                                                           141 double-hummer alignment exceptions   \n",
       "7                                                               CE sym 2, at 0x0b85eee0, mask 0x05   \n",
       "8   ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33569   \n",
       "9   ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33370   \n",
       "10                                                             CE sym 20, at 0x1438f9e0, mask 0x40   \n",
       "11                                                                            generating core.2275   \n",
       "12                                                                             generating core.862   \n",
       "13                                                                             generating core.728   \n",
       "14                                                                             generating core.775   \n",
       "15                                                                            generating core.3276   \n",
       "16                                                                            generating core.1717   \n",
       "17                                                                            generating core.3919   \n",
       "18                                                                            generating core.2079   \n",
       "19                                                                            generating core.1414   \n",
       "\n",
       "    Anomaly Label  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "5               0  \n",
       "6               0  \n",
       "7               0  \n",
       "8               1  \n",
       "9               1  \n",
       "10              0  \n",
       "11              0  \n",
       "12              0  \n",
       "13              0  \n",
       "14              0  \n",
       "15              0  \n",
       "16              0  \n",
       "17              0  \n",
       "18              0  \n",
       "19              0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = pd.read_csv(log_csv_file, names=['Anomaly Type', 'Timestamp (ms)', 'Date', 'Node', 'Timestamp', 'Node Repeat', 'Message Type', 'Component', 'Level', 'Content'])\n",
    "original_df['Anomaly Label'] = np.where(original_df['Anomaly Type'] == '-', 0, 1)\n",
    "original_df.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anomaly Label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>63543 double-hummer alignment exceptions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>162 double-hummer alignment exceptions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>141 double-hummer alignment exceptions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>CE sym 2, at 0x0b85eee0, mask 0x05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>CE sym 20, at 0x1438f9e0, mask 0x40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.2275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.3276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.1717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.3919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.2079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.1414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Anomaly Label  \\\n",
       "0               0   \n",
       "1               0   \n",
       "2               0   \n",
       "3               0   \n",
       "4               0   \n",
       "5               0   \n",
       "6               0   \n",
       "7               0   \n",
       "8               1   \n",
       "9               1   \n",
       "10              0   \n",
       "11              0   \n",
       "12              0   \n",
       "13              0   \n",
       "14              0   \n",
       "15              0   \n",
       "16              0   \n",
       "17              0   \n",
       "18              0   \n",
       "19              0   \n",
       "\n",
       "                                                                                           Content  \n",
       "0                                                         instruction cache parity error corrected  \n",
       "1                                                         instruction cache parity error corrected  \n",
       "2                                                         instruction cache parity error corrected  \n",
       "3                                                         instruction cache parity error corrected  \n",
       "4                                                         63543 double-hummer alignment exceptions  \n",
       "5                                                           162 double-hummer alignment exceptions  \n",
       "6                                                           141 double-hummer alignment exceptions  \n",
       "7                                                               CE sym 2, at 0x0b85eee0, mask 0x05  \n",
       "8   ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33569  \n",
       "9   ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33370  \n",
       "10                                                             CE sym 20, at 0x1438f9e0, mask 0x40  \n",
       "11                                                                            generating core.2275  \n",
       "12                                                                             generating core.862  \n",
       "13                                                                             generating core.728  \n",
       "14                                                                             generating core.775  \n",
       "15                                                                            generating core.3276  \n",
       "16                                                                            generating core.1717  \n",
       "17                                                                            generating core.3919  \n",
       "18                                                                            generating core.2079  \n",
       "19                                                                            generating core.1414  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = original_df[['Anomaly Label', 'Content']]\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Log Sequences and Labels for Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = math.floor(df['Content'].index.size/WINDOW_SIZE)\n",
    "r = math.floor(df['Content'].index.size%WINDOW_SIZE)\n",
    "\n",
    "if r != 0:\n",
    "    log_seqs = np.array(np.split(np.array(df['Content'])[:-r], n))\n",
    "else:\n",
    "    log_seqs = np.array(np.split(np.array(df['Content']), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if r != 0:\n",
    "    log_seq_idx = np.array(np.split(df.index.to_numpy()[:-r], n))\n",
    "else:\n",
    "    log_seq_idx = np.array(np.split(df.index.to_numpy(), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_seq_anomaly_labels = np.empty([n], dtype=int)\n",
    "i = 0\n",
    "for seq in log_seq_idx:\n",
    "    if np.sum(df.loc[seq]['Anomaly Label'].values) > 0:\n",
    "        log_seq_anomaly_labels[i] = 1\n",
    "    else:\n",
    "        log_seq_anomaly_labels[i] = 0\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Parsing & Numericalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drain Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(drain_input_dir + '/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "files = glob.glob(drain_output_dir + '/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "drain_config_file = path.abspath(path.join(project_root, config_dir, '../', 'drain3.ini'))\n",
    "\n",
    "main_structured_csv_filename = 'BGL_main_structured.csv'\n",
    "drain_main_structured_csv_file = path.abspath(path.join(project_root, drain_output_dir, main_structured_csv_filename))\n",
    "\n",
    "templates_csv_filename = 'BGL_main_templates.csv'\n",
    "drain_templates_csv_file = path.abspath(path.join(project_root, drain_output_dir, templates_csv_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrainParser(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        config = TemplateMinerConfig()\n",
    "        config.load(drain_config_file)\n",
    "\n",
    "        self.template_miner = TemplateMiner(config=config)\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, log_seqs, y = None):\n",
    "        log_seqs_list = log_seqs.reshape([-1]).tolist()\n",
    "        self.parsed = []\n",
    "\n",
    "        for line in log_seqs_list:\n",
    "            self.parsed.append(self.template_miner.add_log_message(line))\n",
    "\n",
    "        # Uncomment during debug to view the parser output\n",
    "        # self.write_output_to_csv()\n",
    "\n",
    "        template_seq = [str(x['cluster_id']-1) for x in self.parsed]\n",
    "        n = math.floor(len(template_seq)/WINDOW_SIZE)\n",
    "        template_seqs = np.array(np.split(np.array(template_seq), n))\n",
    "\n",
    "        return template_seqs\n",
    "    \n",
    "    def cluster_template_to_tuple(self, cluster):\n",
    "        return (cluster.cluster_id, cluster.get_template(), cluster.size,)\n",
    "\n",
    "    def write_output_to_csv(self):\n",
    "        with open(drain_main_structured_csv_file, 'w') as drain_main_structured_csv_file_obj:\n",
    "            main_structured_csv_filewriter = DictWriter(drain_main_structured_csv_file_obj, fieldnames=['template_mined', 'cluster_id', 'change_type', 'cluster_size', 'cluster_count'])\n",
    "            main_structured_csv_filewriter.writeheader()\n",
    "            for line in self.parsed:\n",
    "                main_structured_csv_filewriter.writerow(line)\n",
    "            drain_main_structured_csv_file_obj.close\n",
    "            \n",
    "        clusters = self.template_miner.drain.clusters\n",
    "\n",
    "        with open(drain_templates_csv_file, 'a') as drain_templates_csv_file_obj:\n",
    "            drain_templates_csv_filewriter = writer(drain_templates_csv_file_obj)\n",
    "            drain_templates_csv_filewriter.writerow(header for header in ['cluster_id', 'template', 'size'])\n",
    "            for line in clusters:\n",
    "                drain_templates_csv_filewriter.writerow(self.cluster_template_to_tuple(line))\n",
    "            drain_templates_csv_file_obj.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spell Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_content_csv_file_name = 'bgl_2k_content.csv'\n",
    "log_content_csv_file = log_file = path.abspath(path.join(project_root, '../', spell_input_dir, log_content_csv_file_name))\n",
    "\n",
    "main_structured_csv_filename = 'BGL_main_structured.csv'\n",
    "spell_main_structured_csv_file = path.abspath(path.join(project_root, '../', spell_output_dir, main_structured_csv_filename))\n",
    "\n",
    "templates_csv_filename = 'BGL_main_templates.csv'\n",
    "spell_templates_csv_file = path.abspath(path.join(project_root, '../', spell_output_dir, templates_csv_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpellParser(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        log_format = '<Content>'\n",
    "        tau = 0.5\n",
    "\n",
    "        self.parser = spell.LogParser(indir=spell_input_dir, outdir=spell_output_dir,\n",
    "                             log_format=log_format, tau=tau, logmain='BGL')\n",
    "        self.batch_size = 100\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        self.template_seqs = []\n",
    "        return self\n",
    "\n",
    "    def transform(self, log_seqs, y = None):\n",
    "        log_seqs_list = log_seqs.reshape([-1]).tolist()\n",
    "        log_seqs_list = [log_seqs_list[i * self.batch_size :(i+1) * self.batch_size] for i in range((len(log_seqs_list) + self.batch_size - 1) // self.batch_size)]\n",
    "\n",
    "        for log_seqs in log_seqs_list:\n",
    "            ldf = pd.DataFrame(log_seqs, columns=['Content'])\n",
    "            ldf.to_csv(log_content_csv_file, index=False, header=False)\n",
    "\n",
    "            self.parser.parse(log_content_csv_file_name)\n",
    "\n",
    "            nums = self.numericalize()\n",
    "            n = math.floor(len(nums)/WINDOW_SIZE)\n",
    "            self.template_seqs.append(np.array(np.split(nums, n)).reshape([-1]))\n",
    "            \n",
    "            # Comment during debug to view parser output\n",
    "            self.cleanup_files()\n",
    "        \n",
    "        print('template seqs: ', self.template_seqs)\n",
    "\n",
    "        return self.template_seqs\n",
    "\n",
    "    def numericalize(self):\n",
    "        output_df = pd.read_csv(spell_main_structured_csv_file)\n",
    "        template_df = pd.read_csv(spell_templates_csv_file)\n",
    "\n",
    "        vocab = template_df['EventId']\n",
    "        text = output_df['EventId']\n",
    "\n",
    "        num = Numericalize(vocab.to_numpy(), min_freq=1)\n",
    "        num.setup()\n",
    "        nums = np.array(num(text.to_numpy()))\n",
    "\n",
    "        return nums\n",
    "\n",
    "    def cleanup_files(self):\n",
    "        files = glob.glob(spell_input_dir + '/*')\n",
    "        for f in files:\n",
    "            os.remove(f)\n",
    "\n",
    "        files = glob.glob(spell_output_dir + '/*')\n",
    "        for f in files:\n",
    "            os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbedding(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.NUMBER_OF_DIMENSIONS = 100\n",
    "\n",
    "    def fit(self, template_seqs, y = None):\n",
    "        template_seqs_filename = 'bgl_train_seqs.txt'\n",
    "        template_seqs_file = path.abspath(path.join(project_root, spell_output_dir, template_seqs_filename))\n",
    "        np.savetxt(template_seqs_file, template_seqs)\n",
    "        self.fasttext_model = fasttext.train_unsupervised(template_seqs_file, model='cbow', minCount=1, dim=self.NUMBER_OF_DIMENSIONS)\n",
    "        \n",
    "        # Comment during debug to view embedding input\n",
    "        os.remove(template_seqs_file)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, template_seqs, y = None):\n",
    "        template_seqs_ = template_seqs.copy()\n",
    "        template_seqs_ = np.apply_along_axis(self.average_embeddings, 1, template_seqs)\n",
    "\n",
    "        return template_seqs_\n",
    "\n",
    "    def average_embeddings(self, num_lse_vector):\n",
    "        w2v_vector = [self.fasttext_model.get_word_vector(word) for word in np.vectorize(str)(num_lse_vector)]\n",
    "        return np.average(w2v_vector, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbedding_2(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.NUMBER_OF_DIMENSIONS = 100\n",
    "\n",
    "    def fit(self, template_seqs, y = None):\n",
    "        template_seqs_filename = 'bgl_train_seqs.txt'\n",
    "        template_seqs_file = path.abspath(path.join(project_root, spell_output_dir, template_seqs_filename))\n",
    "        np.savetxt(template_seqs_file, template_seqs.astype(int), fmt='%i')\n",
    "        self.fasttext_model = fasttext.train_unsupervised(template_seqs_file, model='cbow', minCount=1, dim=self.NUMBER_OF_DIMENSIONS)\n",
    "        \n",
    "        # Comment during debug to view embedding input\n",
    "        os.remove(template_seqs_file)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, template_seqs, y = None):\n",
    "        template_seqs_ = template_seqs.copy()\n",
    "        template_seqs_ = np.apply_along_axis(self.average_embeddings, 1, template_seqs)\n",
    "\n",
    "        return template_seqs_\n",
    "\n",
    "    def average_embeddings(self, num_lse_vector):\n",
    "        s2v_vector = self.fasttext_model.get_sentence_vector(' '.join(np.vectorize(str)(num_lse_vector)))\n",
    "        return s2v_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
    "for train, test in cv.split(log_seqs, log_seq_anomaly_labels):\n",
    "    print(train.shape, test.shape)\n",
    "\n",
    "drain_pipe = Pipeline(steps=[('parsing', DrainParser()), ('word_embedding', WordEmbedding()), ('gnb', GaussianNB())])\n",
    "drain_pred_log_seq_anomaly_labels = drain_pipe.fit(log_seqs[train], log_seq_anomaly_labels[train]).predict(log_seqs[test])\n",
    "\n",
    "spell_pipe = Pipeline(steps=[('parsing', SpellParser()), ('word_embedding', WordEmbedding()), ('gnb', GaussianNB())])\n",
    "spell_pred_log_seq_anomaly_labels = spell_pipe.fit(log_seqs[train], log_seq_anomaly_labels[train]).predict(log_seqs[test])\n",
    "\n",
    "print(log_seq_anomaly_labels[test])\n",
    "print(drain_pred_log_seq_anomaly_labels)\n",
    "print(spell_pred_log_seq_anomaly_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.read_csv(spell_main_structured_csv_file)\n",
    "nums = output_df['EventId'].to_numpy()\n",
    "n = math.floor(len(nums)/WINDOW_SIZE)\n",
    "nums = np.array(np.split(nums, n))\n",
    "\n",
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n"
     ]
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
    "for train, test in cv.split(log_seqs, log_seq_anomaly_labels):\n",
    "    print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-24 14:00:40,292][WARNING]: config file not found: /home/dsdev/dsml13-ms/final-thesis/impl/loganomalydetection/test/drain3.ini\n",
      "[2022-11-24 14:00:40,294][INFO]: Starting Drain3 template miner\n",
      "[2022-11-24 14:00:40,313][INFO]: Parsing file: input/spell/bgl_2k_content.csv\n",
      "[2022-11-24 14:00:40,316][INFO]: Loaded 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,317][INFO]: load_data() finished!\n",
      "[2022-11-24 14:00:40,326][INFO]: Processed 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,333][INFO]: Output parse file\n",
      "[2022-11-24 14:00:40,336][INFO]: Output main file for append\n",
      "[2022-11-24 14:00:40,342][INFO]: lastestLindId: 100\n",
      "[2022-11-24 14:00:40,351][INFO]: rootNodePath: output/spell/rootNode.pkl\n",
      "[2022-11-24 14:00:40,352][INFO]: logCluLPath: output/spell/logCluL.pkl\n",
      "[2022-11-24 14:00:40,353][INFO]: Store objects done.\n",
      "[2022-11-24 14:00:40,354][INFO]: Parsing done. [Time taken: 0:00:00.040540]\n",
      "[2022-11-24 14:00:40,365][INFO]: Parsing file: input/spell/bgl_2k_content.csv\n",
      "[2022-11-24 14:00:40,367][INFO]: Loaded 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,369][INFO]: load_data() finished!\n",
      "[2022-11-24 14:00:40,379][INFO]: Processed 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,385][INFO]: Output parse file\n",
      "[2022-11-24 14:00:40,390][INFO]: Output main file for append\n",
      "[2022-11-24 14:00:40,398][INFO]: lastestLindId: 100\n",
      "[2022-11-24 14:00:40,406][INFO]: rootNodePath: output/spell/rootNode.pkl\n",
      "[2022-11-24 14:00:40,409][INFO]: logCluLPath: output/spell/logCluL.pkl\n",
      "[2022-11-24 14:00:40,411][INFO]: Store objects done.\n",
      "[2022-11-24 14:00:40,413][INFO]: Parsing done. [Time taken: 0:00:00.048556]\n",
      "[2022-11-24 14:00:40,420][INFO]: Parsing file: input/spell/bgl_2k_content.csv\n",
      "[2022-11-24 14:00:40,423][INFO]: Loaded 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,426][INFO]: load_data() finished!\n",
      "[2022-11-24 14:00:40,437][INFO]: Processed 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,446][INFO]: Output parse file\n",
      "[2022-11-24 14:00:40,450][INFO]: Output main file for append\n",
      "[2022-11-24 14:00:40,456][INFO]: lastestLindId: 100\n",
      "[2022-11-24 14:00:40,466][INFO]: rootNodePath: output/spell/rootNode.pkl\n",
      "[2022-11-24 14:00:40,468][INFO]: logCluLPath: output/spell/logCluL.pkl\n",
      "[2022-11-24 14:00:40,469][INFO]: Store objects done.\n",
      "[2022-11-24 14:00:40,470][INFO]: Parsing done. [Time taken: 0:00:00.049969]\n",
      "[2022-11-24 14:00:40,479][INFO]: Parsing file: input/spell/bgl_2k_content.csv\n",
      "[2022-11-24 14:00:40,482][INFO]: Loaded 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,484][INFO]: load_data() finished!\n",
      "[2022-11-24 14:00:40,495][INFO]: Processed 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,503][INFO]: Output parse file\n",
      "[2022-11-24 14:00:40,506][INFO]: Output main file for append\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-24 14:00:40,514][INFO]: lastestLindId: 100\n",
      "[2022-11-24 14:00:40,525][INFO]: rootNodePath: output/spell/rootNode.pkl\n",
      "[2022-11-24 14:00:40,527][INFO]: logCluLPath: output/spell/logCluL.pkl\n",
      "[2022-11-24 14:00:40,529][INFO]: Store objects done.\n",
      "[2022-11-24 14:00:40,529][INFO]: Parsing done. [Time taken: 0:00:00.050643]\n",
      "[2022-11-24 14:00:40,536][INFO]: Parsing file: input/spell/bgl_2k_content.csv\n",
      "[2022-11-24 14:00:40,538][INFO]: Loaded 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,540][INFO]: load_data() finished!\n",
      "[2022-11-24 14:00:40,549][INFO]: Processed 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,557][INFO]: Output parse file\n",
      "[2022-11-24 14:00:40,560][INFO]: Output main file for append\n",
      "[2022-11-24 14:00:40,565][INFO]: lastestLindId: 100\n",
      "[2022-11-24 14:00:40,572][INFO]: rootNodePath: output/spell/rootNode.pkl\n",
      "[2022-11-24 14:00:40,574][INFO]: logCluLPath: output/spell/logCluL.pkl\n",
      "[2022-11-24 14:00:40,575][INFO]: Store objects done.\n",
      "[2022-11-24 14:00:40,576][INFO]: Parsing done. [Time taken: 0:00:00.039740]\n",
      "[2022-11-24 14:00:40,583][INFO]: Parsing file: input/spell/bgl_2k_content.csv\n",
      "[2022-11-24 14:00:40,586][INFO]: Loaded 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,588][INFO]: load_data() finished!\n",
      "[2022-11-24 14:00:40,598][INFO]: Processed 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,605][INFO]: Output parse file\n",
      "[2022-11-24 14:00:40,610][INFO]: Output main file for append\n",
      "[2022-11-24 14:00:40,616][INFO]: lastestLindId: 100\n",
      "[2022-11-24 14:00:40,625][INFO]: rootNodePath: output/spell/rootNode.pkl\n",
      "[2022-11-24 14:00:40,627][INFO]: logCluLPath: output/spell/logCluL.pkl\n",
      "[2022-11-24 14:00:40,629][INFO]: Store objects done.\n",
      "[2022-11-24 14:00:40,630][INFO]: Parsing done. [Time taken: 0:00:00.046511]\n",
      "[2022-11-24 14:00:40,640][INFO]: Parsing file: input/spell/bgl_2k_content.csv\n",
      "[2022-11-24 14:00:40,643][INFO]: Loaded 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,647][INFO]: load_data() finished!\n",
      "[2022-11-24 14:00:40,655][INFO]: Processed 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,663][INFO]: Output parse file\n",
      "[2022-11-24 14:00:40,666][INFO]: Output main file for append\n",
      "[2022-11-24 14:00:40,671][INFO]: lastestLindId: 100\n",
      "[2022-11-24 14:00:40,680][INFO]: rootNodePath: output/spell/rootNode.pkl\n",
      "[2022-11-24 14:00:40,681][INFO]: logCluLPath: output/spell/logCluL.pkl\n",
      "[2022-11-24 14:00:40,682][INFO]: Store objects done.\n",
      "[2022-11-24 14:00:40,683][INFO]: Parsing done. [Time taken: 0:00:00.043368]\n",
      "[2022-11-24 14:00:40,690][INFO]: Parsing file: input/spell/bgl_2k_content.csv\n",
      "[2022-11-24 14:00:40,692][INFO]: Loaded 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,695][INFO]: load_data() finished!\n",
      "[2022-11-24 14:00:40,702][INFO]: Processed 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,712][INFO]: Output parse file\n",
      "[2022-11-24 14:00:40,714][INFO]: Output main file for append\n",
      "[2022-11-24 14:00:40,720][INFO]: lastestLindId: 100\n",
      "[2022-11-24 14:00:40,727][INFO]: rootNodePath: output/spell/rootNode.pkl\n",
      "[2022-11-24 14:00:40,729][INFO]: logCluLPath: output/spell/logCluL.pkl\n",
      "[2022-11-24 14:00:40,730][INFO]: Store objects done.\n",
      "[2022-11-24 14:00:40,731][INFO]: Parsing done. [Time taken: 0:00:00.041099]\n",
      "[2022-11-24 14:00:40,737][INFO]: Parsing file: input/spell/bgl_2k_content.csv\n",
      "[2022-11-24 14:00:40,739][INFO]: Loaded 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,741][INFO]: load_data() finished!\n",
      "[2022-11-24 14:00:40,749][INFO]: Processed 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,755][INFO]: Output parse file\n",
      "[2022-11-24 14:00:40,759][INFO]: Output main file for append\n",
      "[2022-11-24 14:00:40,765][INFO]: lastestLindId: 100\n",
      "[2022-11-24 14:00:40,774][INFO]: rootNodePath: output/spell/rootNode.pkl\n",
      "[2022-11-24 14:00:40,776][INFO]: logCluLPath: output/spell/logCluL.pkl\n",
      "[2022-11-24 14:00:40,778][INFO]: Store objects done.\n",
      "[2022-11-24 14:00:40,778][INFO]: Parsing done. [Time taken: 0:00:00.041024]\n",
      "[2022-11-24 14:00:40,786][INFO]: Parsing file: input/spell/bgl_2k_content.csv\n",
      "[2022-11-24 14:00:40,789][INFO]: Loaded 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,791][INFO]: load_data() finished!\n",
      "[2022-11-24 14:00:40,802][INFO]: Processed 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,809][INFO]: Output parse file\n",
      "[2022-11-24 14:00:40,812][INFO]: Output main file for append\n",
      "[2022-11-24 14:00:40,819][INFO]: lastestLindId: 100\n",
      "[2022-11-24 14:00:40,828][INFO]: rootNodePath: output/spell/rootNode.pkl\n",
      "[2022-11-24 14:00:40,830][INFO]: logCluLPath: output/spell/logCluL.pkl\n",
      "[2022-11-24 14:00:40,831][INFO]: Store objects done.\n",
      "[2022-11-24 14:00:40,832][INFO]: Parsing done. [Time taken: 0:00:00.045376]\n",
      "[2022-11-24 14:00:40,839][INFO]: Parsing file: input/spell/bgl_2k_content.csv\n",
      "[2022-11-24 14:00:40,842][INFO]: Loaded 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,844][INFO]: load_data() finished!\n",
      "[2022-11-24 14:00:40,855][INFO]: Processed 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,863][INFO]: Output parse file\n",
      "[2022-11-24 14:00:40,867][INFO]: Output main file for append\n",
      "[2022-11-24 14:00:40,871][INFO]: lastestLindId: 100\n",
      "[2022-11-24 14:00:40,879][INFO]: rootNodePath: output/spell/rootNode.pkl\n",
      "[2022-11-24 14:00:40,881][INFO]: logCluLPath: output/spell/logCluL.pkl\n",
      "[2022-11-24 14:00:40,882][INFO]: Store objects done.\n",
      "[2022-11-24 14:00:40,883][INFO]: Parsing done. [Time taken: 0:00:00.043772]\n",
      "[2022-11-24 14:00:40,889][INFO]: Parsing file: input/spell/bgl_2k_content.csv\n",
      "[2022-11-24 14:00:40,892][INFO]: Loaded 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,894][INFO]: load_data() finished!\n",
      "[2022-11-24 14:00:40,905][INFO]: Processed 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,914][INFO]: Output parse file\n",
      "[2022-11-24 14:00:40,918][INFO]: Output main file for append\n",
      "[2022-11-24 14:00:40,925][INFO]: lastestLindId: 100\n",
      "[2022-11-24 14:00:40,933][INFO]: rootNodePath: output/spell/rootNode.pkl\n",
      "[2022-11-24 14:00:40,934][INFO]: logCluLPath: output/spell/logCluL.pkl\n",
      "[2022-11-24 14:00:40,936][INFO]: Store objects done.\n",
      "[2022-11-24 14:00:40,937][INFO]: Parsing done. [Time taken: 0:00:00.047474]\n",
      "[2022-11-24 14:00:40,945][INFO]: Parsing file: input/spell/bgl_2k_content.csv\n",
      "[2022-11-24 14:00:40,947][INFO]: Loaded 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,948][INFO]: load_data() finished!\n",
      "[2022-11-24 14:00:40,956][INFO]: Processed 100.0% of log lines.\n",
      "[2022-11-24 14:00:40,967][INFO]: Output parse file\n",
      "[2022-11-24 14:00:40,978][INFO]: Output main file for append\n",
      "[2022-11-24 14:00:40,988][INFO]: lastestLindId: 100\n",
      "[2022-11-24 14:00:41,001][INFO]: rootNodePath: output/spell/rootNode.pkl\n",
      "[2022-11-24 14:00:41,003][INFO]: logCluLPath: output/spell/logCluL.pkl\n",
      "[2022-11-24 14:00:41,005][INFO]: Store objects done.\n",
      "[2022-11-24 14:00:41,006][INFO]: Parsing done. [Time taken: 0:00:00.061601]\n",
      "[2022-11-24 14:00:41,016][INFO]: Parsing file: input/spell/bgl_2k_content.csv\n",
      "[2022-11-24 14:00:41,019][INFO]: Loaded 100.0% of log lines.\n",
      "[2022-11-24 14:00:41,022][INFO]: load_data() finished!\n",
      "[2022-11-24 14:00:41,033][INFO]: Processed 100.0% of log lines.\n",
      "[2022-11-24 14:00:41,045][INFO]: Output parse file\n",
      "[2022-11-24 14:00:41,048][INFO]: Output main file for append\n",
      "[2022-11-24 14:00:41,055][INFO]: lastestLindId: 100\n",
      "[2022-11-24 14:00:41,064][INFO]: rootNodePath: output/spell/rootNode.pkl\n",
      "[2022-11-24 14:00:41,066][INFO]: logCluLPath: output/spell/logCluL.pkl\n",
      "[2022-11-24 14:00:41,067][INFO]: Store objects done.\n",
      "[2022-11-24 14:00:41,068][INFO]: Parsing done. [Time taken: 0:00:00.051732]\n",
      "[2022-11-24 14:00:41,077][INFO]: Parsing file: input/spell/bgl_2k_content.csv\n",
      "[2022-11-24 14:00:41,080][INFO]: Loaded 100.0% of log lines.\n",
      "[2022-11-24 14:00:41,083][INFO]: load_data() finished!\n",
      "[2022-11-24 14:00:41,097][INFO]: Processed 100.0% of log lines.\n",
      "[2022-11-24 14:00:41,104][INFO]: Output parse file\n",
      "[2022-11-24 14:00:41,109][INFO]: Output main file for append\n",
      "[2022-11-24 14:00:41,116][INFO]: lastestLindId: 100\n",
      "[2022-11-24 14:00:41,123][INFO]: rootNodePath: output/spell/rootNode.pkl\n",
      "[2022-11-24 14:00:41,125][INFO]: logCluLPath: output/spell/logCluL.pkl\n",
      "[2022-11-24 14:00:41,127][INFO]: Store objects done.\n",
      "[2022-11-24 14:00:41,128][INFO]: Parsing done. [Time taken: 0:00:00.050523]\n",
      "[2022-11-24 14:00:41,136][INFO]: Parsing file: input/spell/bgl_2k_content.csv\n",
      "[2022-11-24 14:00:41,138][INFO]: Loaded 100.0% of log lines.\n",
      "[2022-11-24 14:00:41,141][INFO]: load_data() finished!\n",
      "[2022-11-24 14:00:41,153][INFO]: Processed 100.0% of log lines.\n",
      "[2022-11-24 14:00:41,161][INFO]: Output parse file\n",
      "[2022-11-24 14:00:41,165][INFO]: Output main file for append\n",
      "[2022-11-24 14:00:41,170][INFO]: lastestLindId: 100\n",
      "[2022-11-24 14:00:41,180][INFO]: rootNodePath: output/spell/rootNode.pkl\n",
      "[2022-11-24 14:00:41,181][INFO]: logCluLPath: output/spell/logCluL.pkl\n",
      "[2022-11-24 14:00:41,183][INFO]: Store objects done.\n",
      "[2022-11-24 14:00:41,183][INFO]: Parsing done. [Time taken: 0:00:00.047531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "template seqs:  [array([[0, 0, 0, 0, 1],\n",
      "       [1, 1, 2, 3, 3],\n",
      "       [2, 4, 4, 4, 4],\n",
      "       [4, 4, 4, 4, 4],\n",
      "       [4, 4, 4, 4, 4],\n",
      "       [4, 4, 4, 4, 4],\n",
      "       [4, 4, 4, 4, 4],\n",
      "       [4, 4, 4, 4, 4],\n",
      "       [4, 4, 4, 4, 4],\n",
      "       [4, 2, 2, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 4, 4, 5, 4],\n",
      "       [4, 4, 4, 4, 4],\n",
      "       [4, 4, 4, 4, 4],\n",
      "       [4, 4, 4, 4, 6],\n",
      "       [4, 4, 2, 7, 2],\n",
      "       [4, 4, 4, 4, 4],\n",
      "       [4, 4, 2, 4, 4],\n",
      "       [2, 4, 4, 8, 8],\n",
      "       [8, 8, 8, 8, 8]]), array([[0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 2],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 3, 3],\n",
      "       [3, 3, 3, 3, 3],\n",
      "       [4, 4, 4, 4, 4],\n",
      "       [0, 0, 0, 3, 3],\n",
      "       [3, 3, 3, 3, 3],\n",
      "       [3, 0, 3, 3, 5],\n",
      "       [0, 0, 0, 0, 3],\n",
      "       [0, 3, 0, 5, 0]]), array([[ 0,  0,  1,  0,  2],\n",
      "       [ 1,  1,  1,  1,  0],\n",
      "       [ 3,  4,  4,  4,  4],\n",
      "       [ 5,  5,  0,  4,  2],\n",
      "       [ 6,  2,  6,  5,  5],\n",
      "       [ 6,  7,  6,  8,  6],\n",
      "       [ 6,  9,  9,  9, 10],\n",
      "       [ 2,  2, 11,  5, 12],\n",
      "       [11, 13, 13,  0,  0],\n",
      "       [ 5,  7,  5,  5, 14],\n",
      "       [14,  5,  5,  5, 14],\n",
      "       [ 5, 15, 16,  7,  7],\n",
      "       [16, 16,  7, 17, 18],\n",
      "       [19, 11, 11, 17, 11],\n",
      "       [ 7,  7,  7,  7,  7],\n",
      "       [ 6,  6,  6, 20, 21],\n",
      "       [22, 22, 22, 22, 22],\n",
      "       [22, 22, 20, 22, 22],\n",
      "       [20, 20, 20, 20, 20],\n",
      "       [20, 20, 20, 20, 20]]), array([[ 0,  1,  2,  3,  2],\n",
      "       [ 2,  2,  2,  2,  2],\n",
      "       [ 2,  2,  2,  2,  2],\n",
      "       [ 2,  4,  5,  3,  2],\n",
      "       [ 6,  6,  6,  6,  6],\n",
      "       [ 6,  6,  6,  3,  3],\n",
      "       [ 3,  6,  6,  6,  6],\n",
      "       [ 2,  2,  2,  2,  2],\n",
      "       [ 2,  2,  2,  2,  2],\n",
      "       [ 2,  2,  2,  2,  2],\n",
      "       [ 2,  2,  2,  2,  2],\n",
      "       [ 2,  2,  2,  4,  3],\n",
      "       [ 7,  7,  8,  8,  8],\n",
      "       [ 9,  9,  9,  7,  7],\n",
      "       [ 7,  2,  7,  7, 10],\n",
      "       [11,  7,  7,  8,  8],\n",
      "       [ 9,  3, 12,  3,  2],\n",
      "       [ 2,  2,  2,  2,  2],\n",
      "       [ 6,  2,  2,  2,  2],\n",
      "       [ 2,  2,  2,  2,  2]]), array([[0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [1, 2, 1, 1, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [3, 3, 3, 3, 3],\n",
      "       [3, 3, 3, 3, 3],\n",
      "       [3, 3, 3, 3, 3],\n",
      "       [3, 3, 3, 3, 3],\n",
      "       [3, 3, 3, 3, 3],\n",
      "       [3, 3, 3, 3, 3],\n",
      "       [3, 3, 3, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 4, 5, 0, 0],\n",
      "       [0, 0, 0, 0, 0]]), array([[0, 0, 0, 1, 1],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [2, 3, 4, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [1, 2, 3, 3, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 4, 5, 5],\n",
      "       [5, 5, 5, 5, 5],\n",
      "       [5, 5, 5, 5, 5],\n",
      "       [5, 5, 5, 5, 5],\n",
      "       [5, 5, 0, 0, 0]]), array([[0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [2, 3, 0, 0, 0],\n",
      "       [0, 0, 0, 4, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [1, 0, 2, 2, 2],\n",
      "       [2, 2, 2, 2, 2],\n",
      "       [2, 2, 2, 2, 2],\n",
      "       [2, 2, 2, 2, 2],\n",
      "       [2, 2, 2, 2, 2],\n",
      "       [2, 2, 2, 2, 2],\n",
      "       [2, 2, 2, 2, 2],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [2, 2, 2, 2, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [3, 3, 2, 2, 2],\n",
      "       [2, 2, 2, 2, 0]]), array([[ 0,  1,  1,  1,  1],\n",
      "       [ 1,  1,  1,  1,  1],\n",
      "       [ 0,  0,  0,  1,  0],\n",
      "       [ 1,  1,  1,  1,  1],\n",
      "       [ 2,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  3,  4],\n",
      "       [ 4,  5,  6,  7,  8],\n",
      "       [ 4,  8,  9,  9,  9],\n",
      "       [ 9,  9,  9,  9,  9],\n",
      "       [ 9, 10,  7,  5, 10],\n",
      "       [ 8,  8,  5,  8,  5],\n",
      "       [ 2,  2,  2, 11, 11],\n",
      "       [11, 11, 11, 11, 11],\n",
      "       [11, 11, 11, 11, 11]]), array([[ 0,  0,  0,  1,  1],\n",
      "       [ 0,  2,  3,  4,  4],\n",
      "       [ 5,  6,  1,  7,  7],\n",
      "       [ 7,  8,  7,  7,  5],\n",
      "       [ 7,  7,  7,  1,  7],\n",
      "       [ 9, 10, 10,  9,  9],\n",
      "       [10,  9,  9,  9,  9],\n",
      "       [ 9,  9,  9,  9,  9],\n",
      "       [10,  9,  9,  9,  9],\n",
      "       [10,  9,  9,  9,  9],\n",
      "       [ 9,  9,  9,  9, 10],\n",
      "       [10, 10,  9,  9,  9],\n",
      "       [ 9,  9,  9,  9,  9],\n",
      "       [ 9,  5,  8,  5, 11],\n",
      "       [10, 10, 10, 10, 10],\n",
      "       [10, 10, 10, 10,  9],\n",
      "       [ 9,  9,  9,  9,  9],\n",
      "       [ 9,  9,  9,  9,  9],\n",
      "       [12, 12,  5,  8,  7],\n",
      "       [ 5, 13, 13,  8,  1]]), array([[ 0,  1,  2,  3,  4],\n",
      "       [ 5,  0,  6,  7,  8],\n",
      "       [ 7,  7,  4,  1,  7],\n",
      "       [ 0,  9, 10,  0, 11],\n",
      "       [11,  0, 11, 12, 13],\n",
      "       [13, 13, 13, 13, 13],\n",
      "       [13, 13, 13, 13, 13],\n",
      "       [13, 13, 13, 13, 13],\n",
      "       [13, 13, 13, 12, 12],\n",
      "       [13, 13,  6,  6,  6],\n",
      "       [ 6,  6, 14,  6,  6],\n",
      "       [ 0,  0,  0,  0,  7],\n",
      "       [15,  0, 15, 16,  0],\n",
      "       [ 0,  0,  0,  6,  0],\n",
      "       [ 4,  0,  0,  4,  5],\n",
      "       [ 6,  6,  6,  0,  8],\n",
      "       [ 5, 17,  0,  0, 15],\n",
      "       [15,  7, 18, 18, 18],\n",
      "       [18, 18, 18,  0,  0],\n",
      "       [19,  6,  6, 15,  4]]), array([[0, 1, 2, 2, 1],\n",
      "       [1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1],\n",
      "       [2, 2, 2, 1, 1],\n",
      "       [1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1],\n",
      "       [2, 2, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1],\n",
      "       [1, 2, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 2],\n",
      "       [2, 2, 2, 2, 2],\n",
      "       [2, 2, 2, 2, 2],\n",
      "       [2, 2, 2, 2, 2],\n",
      "       [1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1],\n",
      "       [1, 1, 2, 1, 1],\n",
      "       [1, 1, 1, 1, 1]]), array([[ 0,  0,  1,  1,  1],\n",
      "       [ 1,  1,  1,  0,  1],\n",
      "       [ 1,  1,  1,  1,  1],\n",
      "       [ 0,  1,  1,  1,  0],\n",
      "       [ 1,  1,  1,  1,  1],\n",
      "       [ 1,  1,  2,  1,  1],\n",
      "       [ 1,  1,  1,  0,  1],\n",
      "       [ 1,  1,  0,  0,  0],\n",
      "       [ 1,  1,  1,  3,  4],\n",
      "       [ 3,  5,  4,  6,  6],\n",
      "       [ 1,  1,  3,  2,  1],\n",
      "       [ 1,  1,  1,  1,  1],\n",
      "       [ 1,  1,  1,  1,  1],\n",
      "       [ 1,  1,  1,  1,  1],\n",
      "       [ 1,  1,  1,  0,  1],\n",
      "       [ 1,  1,  3,  1,  1],\n",
      "       [ 3,  3,  5,  3,  7],\n",
      "       [ 1,  1,  1,  0,  2],\n",
      "       [ 5,  3,  7,  8,  8],\n",
      "       [ 9,  2,  2,  2, 10]]), array([[ 0,  1,  2,  3,  4],\n",
      "       [ 4,  5,  5,  5,  6],\n",
      "       [ 7,  7,  8,  5,  9],\n",
      "       [ 9,  9,  9,  9,  9],\n",
      "       [ 9,  5, 10, 10,  5],\n",
      "       [10,  5, 10, 10, 10],\n",
      "       [ 5, 10,  5,  5, 10],\n",
      "       [11,  5,  5, 12,  5],\n",
      "       [ 5,  0,  5,  6, 13],\n",
      "       [13, 14, 14, 14, 15],\n",
      "       [15, 15, 15, 15, 14],\n",
      "       [14, 15, 15, 14, 15],\n",
      "       [14, 15, 15, 14, 15],\n",
      "       [14, 15, 15, 14, 15],\n",
      "       [14, 14, 15, 15, 14],\n",
      "       [15, 14, 14, 15, 14],\n",
      "       [15, 14, 15, 15, 14],\n",
      "       [14, 14, 15, 14, 15],\n",
      "       [15, 14, 14, 15, 15],\n",
      "       [15, 14, 14, 15, 15]]), array([[ 0,  0,  0,  0,  0],\n",
      "       [ 1,  1,  1,  0,  0],\n",
      "       [ 1,  2,  0,  1,  1],\n",
      "       [ 1,  1,  1,  1,  1],\n",
      "       [ 1,  1,  0,  1,  0],\n",
      "       [ 1,  0,  0,  1,  1],\n",
      "       [ 0,  1,  1,  1,  1],\n",
      "       [ 1,  0,  0,  1,  0],\n",
      "       [ 0,  0,  1,  1,  2],\n",
      "       [ 2,  2,  3,  4,  5],\n",
      "       [ 6,  2,  2,  2,  2],\n",
      "       [ 2,  2,  3,  2,  3],\n",
      "       [ 7,  8,  9, 10, 11],\n",
      "       [12,  3,  3, 12, 12],\n",
      "       [12, 12, 12, 12, 12],\n",
      "       [12,  3, 13, 14, 14],\n",
      "       [14, 14,  3, 15, 16],\n",
      "       [ 3, 15, 17, 18, 19],\n",
      "       [20, 21, 21, 21, 21],\n",
      "       [21, 21, 21, 21, 17]])]\n",
      "[[0 0 0 0 1]\n",
      " [1 1 2 3 3]\n",
      " [2 4 4 4 4]\n",
      " [4 4 4 4 4]\n",
      " [4 4 4 4 4]\n",
      " [4 4 4 4 4]\n",
      " [4 4 4 4 4]\n",
      " [4 4 4 4 4]\n",
      " [4 4 4 4 4]\n",
      " [4 2 2 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 4 4 5 4]\n",
      " [4 4 4 4 4]\n",
      " [4 4 4 4 4]\n",
      " [4 4 4 4 6]\n",
      " [4 4 2 7 2]\n",
      " [4 4 4 4 4]\n",
      " [4 4 2 4 4]\n",
      " [2 4 4 8 8]\n",
      " [8 8 8 8 8]]\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 1 2]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 3 3]\n",
      " [3 3 3 3 3]\n",
      " [4 4 4 4 4]\n",
      " [0 0 0 3 3]\n",
      " [3 3 3 3 3]\n",
      " [3 0 3 3 5]\n",
      " [0 0 0 0 3]\n",
      " [0 3 0 5 0]]\n",
      "[[ 0  0  1  0  2]\n",
      " [ 1  1  1  1  0]\n",
      " [ 3  4  4  4  4]\n",
      " [ 5  5  0  4  2]\n",
      " [ 6  2  6  5  5]\n",
      " [ 6  7  6  8  6]\n",
      " [ 6  9  9  9 10]\n",
      " [ 2  2 11  5 12]\n",
      " [11 13 13  0  0]\n",
      " [ 5  7  5  5 14]\n",
      " [14  5  5  5 14]\n",
      " [ 5 15 16  7  7]\n",
      " [16 16  7 17 18]\n",
      " [19 11 11 17 11]\n",
      " [ 7  7  7  7  7]\n",
      " [ 6  6  6 20 21]\n",
      " [22 22 22 22 22]\n",
      " [22 22 20 22 22]\n",
      " [20 20 20 20 20]\n",
      " [20 20 20 20 20]]\n",
      "[[ 0  1  2  3  2]\n",
      " [ 2  2  2  2  2]\n",
      " [ 2  2  2  2  2]\n",
      " [ 2  4  5  3  2]\n",
      " [ 6  6  6  6  6]\n",
      " [ 6  6  6  3  3]\n",
      " [ 3  6  6  6  6]\n",
      " [ 2  2  2  2  2]\n",
      " [ 2  2  2  2  2]\n",
      " [ 2  2  2  2  2]\n",
      " [ 2  2  2  2  2]\n",
      " [ 2  2  2  4  3]\n",
      " [ 7  7  8  8  8]\n",
      " [ 9  9  9  7  7]\n",
      " [ 7  2  7  7 10]\n",
      " [11  7  7  8  8]\n",
      " [ 9  3 12  3  2]\n",
      " [ 2  2  2  2  2]\n",
      " [ 6  2  2  2  2]\n",
      " [ 2  2  2  2  2]]\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 2 1 1 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [3 3 3 3 3]\n",
      " [3 3 3 3 3]\n",
      " [3 3 3 3 3]\n",
      " [3 3 3 3 3]\n",
      " [3 3 3 3 3]\n",
      " [3 3 3 3 3]\n",
      " [3 3 3 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 4 5 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[0 0 0 1 1]\n",
      " [0 0 0 0 0]\n",
      " [2 3 4 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 2 3 3 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 4 5 5]\n",
      " [5 5 5 5 5]\n",
      " [5 5 5 5 5]\n",
      " [5 5 5 5 5]\n",
      " [5 5 0 0 0]]\n",
      "[[0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [2 3 0 0 0]\n",
      " [0 0 0 4 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 0 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [2 2 2 2 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [3 3 2 2 2]\n",
      " [2 2 2 2 0]]\n",
      "[[ 0  1  1  1  1]\n",
      " [ 1  1  1  1  1]\n",
      " [ 0  0  0  1  0]\n",
      " [ 1  1  1  1  1]\n",
      " [ 2  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  3  4]\n",
      " [ 4  5  6  7  8]\n",
      " [ 4  8  9  9  9]\n",
      " [ 9  9  9  9  9]\n",
      " [ 9 10  7  5 10]\n",
      " [ 8  8  5  8  5]\n",
      " [ 2  2  2 11 11]\n",
      " [11 11 11 11 11]\n",
      " [11 11 11 11 11]]\n",
      "[[ 0  0  0  1  1]\n",
      " [ 0  2  3  4  4]\n",
      " [ 5  6  1  7  7]\n",
      " [ 7  8  7  7  5]\n",
      " [ 7  7  7  1  7]\n",
      " [ 9 10 10  9  9]\n",
      " [10  9  9  9  9]\n",
      " [ 9  9  9  9  9]\n",
      " [10  9  9  9  9]\n",
      " [10  9  9  9  9]\n",
      " [ 9  9  9  9 10]\n",
      " [10 10  9  9  9]\n",
      " [ 9  9  9  9  9]\n",
      " [ 9  5  8  5 11]\n",
      " [10 10 10 10 10]\n",
      " [10 10 10 10  9]\n",
      " [ 9  9  9  9  9]\n",
      " [ 9  9  9  9  9]\n",
      " [12 12  5  8  7]\n",
      " [ 5 13 13  8  1]]\n",
      "[[ 0  1  2  3  4]\n",
      " [ 5  0  6  7  8]\n",
      " [ 7  7  4  1  7]\n",
      " [ 0  9 10  0 11]\n",
      " [11  0 11 12 13]\n",
      " [13 13 13 13 13]\n",
      " [13 13 13 13 13]\n",
      " [13 13 13 13 13]\n",
      " [13 13 13 12 12]\n",
      " [13 13  6  6  6]\n",
      " [ 6  6 14  6  6]\n",
      " [ 0  0  0  0  7]\n",
      " [15  0 15 16  0]\n",
      " [ 0  0  0  6  0]\n",
      " [ 4  0  0  4  5]\n",
      " [ 6  6  6  0  8]\n",
      " [ 5 17  0  0 15]\n",
      " [15  7 18 18 18]\n",
      " [18 18 18  0  0]\n",
      " [19  6  6 15  4]]\n",
      "[[0 1 2 2 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [2 2 2 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [2 2 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 2 1 1 1]\n",
      " [1 1 1 1 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 2 1 1]\n",
      " [1 1 1 1 1]]\n",
      "[[ 0  0  1  1  1]\n",
      " [ 1  1  1  0  1]\n",
      " [ 1  1  1  1  1]\n",
      " [ 0  1  1  1  0]\n",
      " [ 1  1  1  1  1]\n",
      " [ 1  1  2  1  1]\n",
      " [ 1  1  1  0  1]\n",
      " [ 1  1  0  0  0]\n",
      " [ 1  1  1  3  4]\n",
      " [ 3  5  4  6  6]\n",
      " [ 1  1  3  2  1]\n",
      " [ 1  1  1  1  1]\n",
      " [ 1  1  1  1  1]\n",
      " [ 1  1  1  1  1]\n",
      " [ 1  1  1  0  1]\n",
      " [ 1  1  3  1  1]\n",
      " [ 3  3  5  3  7]\n",
      " [ 1  1  1  0  2]\n",
      " [ 5  3  7  8  8]\n",
      " [ 9  2  2  2 10]]\n",
      "[[ 0  1  2  3  4]\n",
      " [ 4  5  5  5  6]\n",
      " [ 7  7  8  5  9]\n",
      " [ 9  9  9  9  9]\n",
      " [ 9  5 10 10  5]\n",
      " [10  5 10 10 10]\n",
      " [ 5 10  5  5 10]\n",
      " [11  5  5 12  5]\n",
      " [ 5  0  5  6 13]\n",
      " [13 14 14 14 15]\n",
      " [15 15 15 15 14]\n",
      " [14 15 15 14 15]\n",
      " [14 15 15 14 15]\n",
      " [14 15 15 14 15]\n",
      " [14 14 15 15 14]\n",
      " [15 14 14 15 14]\n",
      " [15 14 15 15 14]\n",
      " [14 14 15 14 15]\n",
      " [15 14 14 15 15]\n",
      " [15 14 14 15 15]]\n",
      "[[ 0  0  0  0  0]\n",
      " [ 1  1  1  0  0]\n",
      " [ 1  2  0  1  1]\n",
      " [ 1  1  1  1  1]\n",
      " [ 1  1  0  1  0]\n",
      " [ 1  0  0  1  1]\n",
      " [ 0  1  1  1  1]\n",
      " [ 1  0  0  1  0]\n",
      " [ 0  0  1  1  2]\n",
      " [ 2  2  3  4  5]\n",
      " [ 6  2  2  2  2]\n",
      " [ 2  2  3  2  3]\n",
      " [ 7  8  9 10 11]\n",
      " [12  3  3 12 12]\n",
      " [12 12 12 12 12]\n",
      " [12  3 13 14 14]\n",
      " [14 14  3 15 16]\n",
      " [ 3 15 17 18 19]\n",
      " [20 21 21 21 21]\n",
      " [21 21 21 21 17]]\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(spell_input_dir + '/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "files = glob.glob(spell_output_dir + '/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "test_log_seqs = log_seqs[train]\n",
    "test_log_seq_anomaly_labels = log_seq_anomaly_labels[train]\n",
    "\n",
    "# drain_parser = DrainParser()\n",
    "# drain_parser.fit(test_log_seqs, test_log_seq_anomaly_labels)\n",
    "# drain_template_seqs_output = drain_parser.transform(test_log_seqs, test_log_seq_anomaly_labels)\n",
    "# for templ_seq in drain_template_seqs_output:\n",
    "#     print(type(templ_seq[0]))\n",
    "\n",
    "spell_parser = SpellParser()\n",
    "spell_parser.fit(test_log_seqs, test_log_seq_anomaly_labels)\n",
    "spell_template_seqs_output = spell_parser.transform(test_log_seqs, test_log_seq_anomaly_labels)\n",
    "for templ_seq in spell_template_seqs_output:\n",
    "    print(templ_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for templ_seq in drain_template_seqs_output:\n",
    "    print(type(str(templ_seq[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_seqs_filename = 'bgl_train_seqs.txt'\n",
    "template_seqs_file = path.abspath(path.join(project_root, spell_output_dir, template_seqs_filename))\n",
    "np.savetxt(template_seqs_file, drain_template_seqs_output,fmt='%s')\n",
    "\n",
    "type(drain_template_seqs_output[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drain_embedding = WordEmbedding()\n",
    "drain_embedding.fit(drain_template_seqs_output, log_seq_anomaly_labels[train])\n",
    "drain_word_vector_avg = drain_embedding.transform(drain_template_seqs_output, log_seq_anomaly_labels[train])\n",
    "for wv_avg in drain_word_vector_avg:\n",
    "    print(wv_avg)\n",
    "\n",
    "print('*****************************************************************************************************')\n",
    "\n",
    "# spell_embedding = WordEmbedding()\n",
    "# spell_embedding.fit(spell_template_seqs_output, log_seq_anomaly_labels[train])\n",
    "# spell_word_vector_avg = spell_embedding.transform(spell_template_seqs_output, log_seq_anomaly_labels[train])\n",
    "\n",
    "# for wv_avg in spell_word_vector_avg:\n",
    "#     print(wv_avg)\n",
    "\n",
    "# spell_embedding = WordEmbedding_2()\n",
    "# spell_embedding.fit(spell_template_seqs_output, log_seq_anomaly_labels[train])\n",
    "# spell_word_vector_avg = spell_embedding.transform(spell_template_seqs_output, log_seq_anomaly_labels[train])\n",
    "\n",
    "# for wv_avg in spell_word_vector_avg:\n",
    "#     print(wv_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spell_word_vector_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastai_numericalize():\n",
    "    output_df = pd.read_csv(spell_main_structured_csv_file)\n",
    "    template_df = pd.read_csv(spell_templates_csv_file)\n",
    "\n",
    "    vocab = template_df['EventId']\n",
    "    text = output_df['EventId']\n",
    "\n",
    "    num = Numericalize(vocab.to_numpy(), min_freq=1)\n",
    "    num.setup()\n",
    "    nums = np.array(num(text.to_numpy()))\n",
    "\n",
    "    return nums\n",
    "\n",
    "len(fastai_numericalize())/WINDOW_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_numericalize():\n",
    "    output_df = pd.read_csv(spell_main_structured_csv_file)\n",
    "    template_df = pd.read_csv(spell_templates_csv_file)\n",
    "\n",
    "    vocab = template_df['EventId']\n",
    "    text = output_df['EventId']\n",
    "\n",
    "    print(vocab)\n",
    "    print(text)\n",
    "    nums = []\n",
    "\n",
    "    return nums\n",
    "\n",
    "len(custom_numericalize())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7d5d95ec871826f4c96f39204edc263930b1065d3d6b0d23c0891d0cf865f41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
