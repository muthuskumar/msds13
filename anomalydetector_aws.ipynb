{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Contants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "import glob\n",
    "import boto3\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from csv import (writer, DictWriter)\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from drain3 import TemplateMiner\n",
    "from drain3.template_miner_config import TemplateMinerConfig\n",
    "\n",
    "from spellpy import spell\n",
    "\n",
    "import fasttext\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import (auc, roc_curve, average_precision_score, precision_recall_curve, f1_score, accuracy_score,\n",
    "                            recall_score, precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = os.getcwd()\n",
    "\n",
    "data_dir = 'data'\n",
    "log_file_name = 'bgl_2k.log'\n",
    "\n",
    "config_dir = 'config'\n",
    "\n",
    "input_dir = 'input'\n",
    "spell_output_dir = 'output'\n",
    "\n",
    "spell_input_dir = 'input/spell'\n",
    "spell_output_dir = 'output/spell'\n",
    "\n",
    "drain_input_dir = 'input/drain'\n",
    "drain_output_dir = 'output/drain'\n",
    "\n",
    "WINDOW_SIZE = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert BGL.log file to CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_csv_file_name = 'bgl_2k.csv'\n",
    "log_csv_file = log_file = path.abspath(path.join(project_root, input_dir, log_csv_file_name))\n",
    "\n",
    "if os.path.exists(log_csv_file):\n",
    "    os.remove(log_csv_file)\n",
    "#log_file = path.abspath(path.join(project_root, data_dir, log_file_name))\n",
    "role = get_execution_role()\n",
    "s3 = boto3.client('s3')\n",
    "log_file = s3.get_object(Bucket = 'sagemaker-studio-326787221562-jycpwz9gs3f', Key = 'BGL.csv')\n",
    "log_csv_file = log_file['Body']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anomaly Type</th>\n",
       "      <th>Timestamp (ms)</th>\n",
       "      <th>Date</th>\n",
       "      <th>Node</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Node Repeat</th>\n",
       "      <th>Message Type</th>\n",
       "      <th>Component</th>\n",
       "      <th>Level</th>\n",
       "      <th>Content</th>\n",
       "      <th>Anomaly Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-</td>\n",
       "      <td>1117838570</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03-15.42.50.675872</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>1117838573</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03-15.42.53.276129</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>1117838976</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03-15.49.36.156884</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-</td>\n",
       "      <td>1117838978</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03-15.49.38.026704</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-</td>\n",
       "      <td>1117842440</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R23-M0-NE-C:J05-U01</td>\n",
       "      <td>2005-06-03-16.47.20.730545</td>\n",
       "      <td>R23-M0-NE-C:J05-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>63543 double-hummer alignment exceptions</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-</td>\n",
       "      <td>1117842974</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R24-M0-N1-C:J13-U11</td>\n",
       "      <td>2005-06-03-16.56.14.254137</td>\n",
       "      <td>R24-M0-N1-C:J13-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>162 double-hummer alignment exceptions</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-</td>\n",
       "      <td>1117843015</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R21-M1-N6-C:J08-U11</td>\n",
       "      <td>2005-06-03-16.56.55.309974</td>\n",
       "      <td>R21-M1-N6-C:J08-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>141 double-hummer alignment exceptions</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-</td>\n",
       "      <td>1117848119</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R16-M1-N2-C:J17-U01</td>\n",
       "      <td>2005-06-03-18.21.59.871925</td>\n",
       "      <td>R16-M1-N2-C:J17-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>CE sym 2, at 0x0b85eee0, mask 0x05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>APPREAD</td>\n",
       "      <td>1117869872</td>\n",
       "      <td>2005.06.04</td>\n",
       "      <td>R04-M1-N4-I:J18-U11</td>\n",
       "      <td>2005-06-04-00.24.32.432192</td>\n",
       "      <td>R04-M1-N4-I:J18-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>APP</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33569</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>APPREAD</td>\n",
       "      <td>1117869876</td>\n",
       "      <td>2005.06.04</td>\n",
       "      <td>R27-M1-N4-I:J18-U01</td>\n",
       "      <td>2005-06-04-00.24.36.222560</td>\n",
       "      <td>R27-M1-N4-I:J18-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>APP</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-</td>\n",
       "      <td>1117942120</td>\n",
       "      <td>2005.06.04</td>\n",
       "      <td>R30-M0-N7-C:J08-U01</td>\n",
       "      <td>2005-06-04-20.28.40.767551</td>\n",
       "      <td>R30-M0-N7-C:J08-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>CE sym 20, at 0x1438f9e0, mask 0x40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-</td>\n",
       "      <td>1117955341</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R25-M0-N7-C:J02-U01</td>\n",
       "      <td>2005-06-05-00.09.01.903373</td>\n",
       "      <td>R25-M0-N7-C:J02-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.2275</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-</td>\n",
       "      <td>1117955392</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R24-M1-N8-C:J09-U11</td>\n",
       "      <td>2005-06-05-00.09.52.516674</td>\n",
       "      <td>R24-M1-N8-C:J09-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.862</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-</td>\n",
       "      <td>1117956980</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R24-M1-NB-C:J15-U11</td>\n",
       "      <td>2005-06-05-00.36.20.945796</td>\n",
       "      <td>R24-M1-NB-C:J15-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.728</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-</td>\n",
       "      <td>1117957045</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R20-M1-N8-C:J04-U01</td>\n",
       "      <td>2005-06-05-00.37.25.012681</td>\n",
       "      <td>R20-M1-N8-C:J04-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-</td>\n",
       "      <td>1117959501</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R24-M0-NE-C:J14-U11</td>\n",
       "      <td>2005-06-05-01.18.21.778604</td>\n",
       "      <td>R24-M0-NE-C:J14-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.3276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-</td>\n",
       "      <td>1117959513</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R21-M1-N2-C:J11-U01</td>\n",
       "      <td>2005-06-05-01.18.33.830595</td>\n",
       "      <td>R21-M1-N2-C:J11-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.1717</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-</td>\n",
       "      <td>1117959563</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R24-M0-N8-C:J04-U11</td>\n",
       "      <td>2005-06-05-01.19.23.822135</td>\n",
       "      <td>R24-M0-N8-C:J04-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.3919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-</td>\n",
       "      <td>1117973759</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R31-M0-NE-C:J05-U11</td>\n",
       "      <td>2005-06-05-05.15.59.416717</td>\n",
       "      <td>R31-M0-NE-C:J05-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.2079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-</td>\n",
       "      <td>1117973786</td>\n",
       "      <td>2005.06.05</td>\n",
       "      <td>R36-M0-NA-C:J06-U01</td>\n",
       "      <td>2005-06-05-05.16.26.686603</td>\n",
       "      <td>R36-M0-NA-C:J06-U01</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>generating core.1414</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Anomaly Type  Timestamp (ms)        Date                 Node  \\\n",
       "0             -      1117838570  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "1             -      1117838573  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "2             -      1117838976  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "3             -      1117838978  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "4             -      1117842440  2005.06.03  R23-M0-NE-C:J05-U01   \n",
       "5             -      1117842974  2005.06.03  R24-M0-N1-C:J13-U11   \n",
       "6             -      1117843015  2005.06.03  R21-M1-N6-C:J08-U11   \n",
       "7             -      1117848119  2005.06.03  R16-M1-N2-C:J17-U01   \n",
       "8       APPREAD      1117869872  2005.06.04  R04-M1-N4-I:J18-U11   \n",
       "9       APPREAD      1117869876  2005.06.04  R27-M1-N4-I:J18-U01   \n",
       "10            -      1117942120  2005.06.04  R30-M0-N7-C:J08-U01   \n",
       "11            -      1117955341  2005.06.05  R25-M0-N7-C:J02-U01   \n",
       "12            -      1117955392  2005.06.05  R24-M1-N8-C:J09-U11   \n",
       "13            -      1117956980  2005.06.05  R24-M1-NB-C:J15-U11   \n",
       "14            -      1117957045  2005.06.05  R20-M1-N8-C:J04-U01   \n",
       "15            -      1117959501  2005.06.05  R24-M0-NE-C:J14-U11   \n",
       "16            -      1117959513  2005.06.05  R21-M1-N2-C:J11-U01   \n",
       "17            -      1117959563  2005.06.05  R24-M0-N8-C:J04-U11   \n",
       "18            -      1117973759  2005.06.05  R31-M0-NE-C:J05-U11   \n",
       "19            -      1117973786  2005.06.05  R36-M0-NA-C:J06-U01   \n",
       "\n",
       "                     Timestamp          Node Repeat Message Type Component  \\\n",
       "0   2005-06-03-15.42.50.675872  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "1   2005-06-03-15.42.53.276129  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "2   2005-06-03-15.49.36.156884  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "3   2005-06-03-15.49.38.026704  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "4   2005-06-03-16.47.20.730545  R23-M0-NE-C:J05-U01          RAS    KERNEL   \n",
       "5   2005-06-03-16.56.14.254137  R24-M0-N1-C:J13-U11          RAS    KERNEL   \n",
       "6   2005-06-03-16.56.55.309974  R21-M1-N6-C:J08-U11          RAS    KERNEL   \n",
       "7   2005-06-03-18.21.59.871925  R16-M1-N2-C:J17-U01          RAS    KERNEL   \n",
       "8   2005-06-04-00.24.32.432192  R04-M1-N4-I:J18-U11          RAS       APP   \n",
       "9   2005-06-04-00.24.36.222560  R27-M1-N4-I:J18-U01          RAS       APP   \n",
       "10  2005-06-04-20.28.40.767551  R30-M0-N7-C:J08-U01          RAS    KERNEL   \n",
       "11  2005-06-05-00.09.01.903373  R25-M0-N7-C:J02-U01          RAS    KERNEL   \n",
       "12  2005-06-05-00.09.52.516674  R24-M1-N8-C:J09-U11          RAS    KERNEL   \n",
       "13  2005-06-05-00.36.20.945796  R24-M1-NB-C:J15-U11          RAS    KERNEL   \n",
       "14  2005-06-05-00.37.25.012681  R20-M1-N8-C:J04-U01          RAS    KERNEL   \n",
       "15  2005-06-05-01.18.21.778604  R24-M0-NE-C:J14-U11          RAS    KERNEL   \n",
       "16  2005-06-05-01.18.33.830595  R21-M1-N2-C:J11-U01          RAS    KERNEL   \n",
       "17  2005-06-05-01.19.23.822135  R24-M0-N8-C:J04-U11          RAS    KERNEL   \n",
       "18  2005-06-05-05.15.59.416717  R31-M0-NE-C:J05-U11          RAS    KERNEL   \n",
       "19  2005-06-05-05.16.26.686603  R36-M0-NA-C:J06-U01          RAS    KERNEL   \n",
       "\n",
       "    Level  \\\n",
       "0    INFO   \n",
       "1    INFO   \n",
       "2    INFO   \n",
       "3    INFO   \n",
       "4    INFO   \n",
       "5    INFO   \n",
       "6    INFO   \n",
       "7    INFO   \n",
       "8   FATAL   \n",
       "9   FATAL   \n",
       "10   INFO   \n",
       "11   INFO   \n",
       "12   INFO   \n",
       "13   INFO   \n",
       "14   INFO   \n",
       "15   INFO   \n",
       "16   INFO   \n",
       "17   INFO   \n",
       "18   INFO   \n",
       "19   INFO   \n",
       "\n",
       "                                                                                           Content  \\\n",
       "0                                                         instruction cache parity error corrected   \n",
       "1                                                         instruction cache parity error corrected   \n",
       "2                                                         instruction cache parity error corrected   \n",
       "3                                                         instruction cache parity error corrected   \n",
       "4                                                         63543 double-hummer alignment exceptions   \n",
       "5                                                           162 double-hummer alignment exceptions   \n",
       "6                                                           141 double-hummer alignment exceptions   \n",
       "7                                                               CE sym 2, at 0x0b85eee0, mask 0x05   \n",
       "8   ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33569   \n",
       "9   ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33370   \n",
       "10                                                             CE sym 20, at 0x1438f9e0, mask 0x40   \n",
       "11                                                                            generating core.2275   \n",
       "12                                                                             generating core.862   \n",
       "13                                                                             generating core.728   \n",
       "14                                                                             generating core.775   \n",
       "15                                                                            generating core.3276   \n",
       "16                                                                            generating core.1717   \n",
       "17                                                                            generating core.3919   \n",
       "18                                                                            generating core.2079   \n",
       "19                                                                            generating core.1414   \n",
       "\n",
       "    Anomaly Label  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "5               0  \n",
       "6               0  \n",
       "7               0  \n",
       "8               1  \n",
       "9               1  \n",
       "10              0  \n",
       "11              0  \n",
       "12              0  \n",
       "13              0  \n",
       "14              0  \n",
       "15              0  \n",
       "16              0  \n",
       "17              0  \n",
       "18              0  \n",
       "19              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = pd.read_csv(log_csv_file, names=['Anomaly Type', 'Timestamp (ms)', 'Date', 'Node', 'Timestamp', 'Node Repeat', 'Message Type', 'Component', 'Level', 'Content'])\n",
    "original_df['Anomaly Label'] = np.where(original_df['Anomaly Type'] == '-', 0, 1)\n",
    "original_df.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anomaly Label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>63543 double-hummer alignment exceptions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>162 double-hummer alignment exceptions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>141 double-hummer alignment exceptions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>CE sym 2, at 0x0b85eee0, mask 0x05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>CE sym 20, at 0x1438f9e0, mask 0x40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.2275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.3276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.1717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.3919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.2079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>generating core.1414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Anomaly Label  \\\n",
       "0               0   \n",
       "1               0   \n",
       "2               0   \n",
       "3               0   \n",
       "4               0   \n",
       "5               0   \n",
       "6               0   \n",
       "7               0   \n",
       "8               1   \n",
       "9               1   \n",
       "10              0   \n",
       "11              0   \n",
       "12              0   \n",
       "13              0   \n",
       "14              0   \n",
       "15              0   \n",
       "16              0   \n",
       "17              0   \n",
       "18              0   \n",
       "19              0   \n",
       "\n",
       "                                                                                           Content  \n",
       "0                                                         instruction cache parity error corrected  \n",
       "1                                                         instruction cache parity error corrected  \n",
       "2                                                         instruction cache parity error corrected  \n",
       "3                                                         instruction cache parity error corrected  \n",
       "4                                                         63543 double-hummer alignment exceptions  \n",
       "5                                                           162 double-hummer alignment exceptions  \n",
       "6                                                           141 double-hummer alignment exceptions  \n",
       "7                                                               CE sym 2, at 0x0b85eee0, mask 0x05  \n",
       "8   ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33569  \n",
       "9   ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33370  \n",
       "10                                                             CE sym 20, at 0x1438f9e0, mask 0x40  \n",
       "11                                                                            generating core.2275  \n",
       "12                                                                             generating core.862  \n",
       "13                                                                             generating core.728  \n",
       "14                                                                             generating core.775  \n",
       "15                                                                            generating core.3276  \n",
       "16                                                                            generating core.1717  \n",
       "17                                                                            generating core.3919  \n",
       "18                                                                            generating core.2079  \n",
       "19                                                                            generating core.1414  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = original_df[['Anomaly Label', 'Content']]\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Log Sequences and Labels for Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = math.floor(df['Content'].index.size/WINDOW_SIZE)\n",
    "r = math.floor(df['Content'].index.size%WINDOW_SIZE)\n",
    "\n",
    "if r != 0:\n",
    "    log_seqs = np.array(np.split(np.array(df['Content'])[:-r], n))\n",
    "else:\n",
    "    log_seqs = np.array(np.split(np.array(df['Content']), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if r != 0:\n",
    "    log_seq_idx = np.array(np.split(df.index.to_numpy()[:-r], n))\n",
    "else:\n",
    "    log_seq_idx = np.array(np.split(df.index.to_numpy(), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_seq_anomaly_labels = np.empty([n], dtype=int)\n",
    "i = 0\n",
    "for seq in log_seq_idx:\n",
    "    if np.sum(df.loc[seq]['Anomaly Label'].values) > 0:\n",
    "        log_seq_anomaly_labels[i] = 1\n",
    "    else:\n",
    "        log_seq_anomaly_labels[i] = 0\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Parsing & Numericalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drain Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(drain_input_dir + '/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "files = glob.glob(drain_output_dir + '/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "drain_config_file = path.abspath(path.join(project_root, config_dir, 'drain3.ini'))\n",
    "\n",
    "main_structured_csv_filename = 'BGL_main_structured.csv'\n",
    "drain_main_structured_csv_file = path.abspath(path.join(project_root, drain_output_dir, main_structured_csv_filename))\n",
    "\n",
    "templates_csv_filename = 'BGL_main_templates.csv'\n",
    "drain_templates_csv_file = path.abspath(path.join(project_root, drain_output_dir, templates_csv_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrainParser(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        config = TemplateMinerConfig()\n",
    "        config.load(drain_config_file)\n",
    "\n",
    "        self.template_miner = TemplateMiner(config=config)\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, log_seqs, y = None):\n",
    "        log_seqs_list = log_seqs.reshape([-1]).tolist()\n",
    "        self.parsed = []\n",
    "\n",
    "        for line in log_seqs_list:\n",
    "            self.parsed.append(self.template_miner.add_log_message(line))\n",
    "\n",
    "        # Uncomment during debug to view the parser output\n",
    "        # self.write_output_to_csv()\n",
    "\n",
    "        template_seq = [x['cluster_id']-1 for x in self.parsed]\n",
    "        n = math.floor(len(template_seq)/WINDOW_SIZE)\n",
    "        template_seqs = np.array(np.split(np.array(template_seq), n))\n",
    "\n",
    "        return template_seqs\n",
    "    \n",
    "    def cluster_template_to_tuple(self, cluster):\n",
    "        return (cluster.cluster_id, cluster.get_template(), cluster.size,)\n",
    "\n",
    "    def write_output_to_csv(self):\n",
    "        with open(drain_main_structured_csv_file, 'w') as drain_main_structured_csv_file_obj:\n",
    "            main_structured_csv_filewriter = DictWriter(drain_main_structured_csv_file_obj, fieldnames=['template_mined', 'cluster_id', 'change_type', 'cluster_size', 'cluster_count'])\n",
    "            main_structured_csv_filewriter.writeheader()\n",
    "            for line in self.parsed:\n",
    "                main_structured_csv_filewriter.writerow(line)\n",
    "            drain_main_structured_csv_file_obj.close\n",
    "            \n",
    "        clusters = self.template_miner.drain.clusters\n",
    "\n",
    "        with open(drain_templates_csv_file, 'a') as drain_templates_csv_file_obj:\n",
    "            drain_templates_csv_filewriter = writer(drain_templates_csv_file_obj)\n",
    "            drain_templates_csv_filewriter.writerow(header for header in ['cluster_id', 'template', 'size'])\n",
    "            for line in clusters:\n",
    "                drain_templates_csv_filewriter.writerow(self.cluster_template_to_tuple(line))\n",
    "            drain_templates_csv_file_obj.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spell Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_content_csv_file_name = 'bgl_2k_content.csv'\n",
    "log_content_csv_file = log_file = path.abspath(path.join(project_root, spell_input_dir, log_content_csv_file_name))\n",
    "\n",
    "main_structured_csv_filename = 'BGL_main_structured.csv'\n",
    "spell_main_structured_csv_file = path.abspath(path.join(project_root, spell_output_dir, main_structured_csv_filename))\n",
    "\n",
    "templates_csv_filename = 'BGL_main_templates.csv'\n",
    "spell_templates_csv_file = path.abspath(path.join(project_root, spell_output_dir, templates_csv_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpellParser(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        log_format = '<Content>'\n",
    "        tau = 0.5\n",
    "\n",
    "        self.parser = spell.LogParser(indir=spell_input_dir, outdir=spell_output_dir,\n",
    "                             log_format=log_format, tau=tau, logmain='BGL')\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, log_seqs, y = None):\n",
    "        log_seqs_list = log_seqs.reshape([-1]).tolist()\n",
    "\n",
    "        ldf = pd.DataFrame(log_seqs_list, columns=['Content'])\n",
    "        ldf.to_csv(log_content_csv_file, index=False, header=False)\n",
    "\n",
    "        self.parser.parse(log_content_csv_file_name)\n",
    "\n",
    "        nums = self.numericalize()\n",
    "        n = math.floor(len(nums)/WINDOW_SIZE)\n",
    "        nums = np.array(np.split(nums, n))\n",
    "        \n",
    "        # Comment during debug to view parser output\n",
    "        self.cleanup_files()\n",
    "        \n",
    "        return nums\n",
    "\n",
    "    def numericalize(self):\n",
    "        output_df = pd.read_csv(spell_main_structured_csv_file)\n",
    "\n",
    "        return output_df['EventId'].to_numpy()\n",
    "\n",
    "    def cleanup_files(self):\n",
    "        files = glob.glob(spell_input_dir + '/*')\n",
    "        for f in files:\n",
    "            os.remove(f)\n",
    "\n",
    "        files = glob.glob(spell_output_dir + '/*')\n",
    "        for f in files:\n",
    "            os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbedding(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.NUMBER_OF_DIMENSIONS = 100\n",
    "\n",
    "    def fit(self, template_seqs, y = None):\n",
    "        template_seqs_filename = 'bgl_train_seqs.txt'\n",
    "        template_seqs_file = path.abspath(path.join(project_root, spell_output_dir, template_seqs_filename))\n",
    "        np.savetxt(template_seqs_file, template_seqs, fmt='%s')\n",
    "        self.fasttext_model = fasttext.train_unsupervised(template_seqs_file, model='cbow', minCount=1, dim=self.NUMBER_OF_DIMENSIONS)\n",
    "        \n",
    "        # Comment during debug to view embedding input\n",
    "        os.remove(template_seqs_file)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, template_seqs, y = None):\n",
    "        template_seqs_ = template_seqs.copy()\n",
    "        template_seqs_ = np.apply_along_axis(self.average_embeddings, 1, template_seqs)\n",
    "\n",
    "        return template_seqs_\n",
    "\n",
    "    def average_embeddings(self, num_lse_vector):\n",
    "        s2v_vector = self.fasttext_model.get_sentence_vector(' '.join(np.vectorize(str)(num_lse_vector)))\n",
    "        return s2v_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-22 18:19:53,091][INFO]: Starting Drain3 template miner\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n",
      "(320,) (80,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  97\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:    8755 lr:  0.000000 avg.loss:  4.127273 ETA:   0h 0m 0s\n",
      "[2022-11-22 18:19:53,936][INFO]: Parsing file: input/spell/bgl_2k_content.csv\n",
      "[2022-11-22 18:19:53,959][INFO]: Loaded 100.0% of log lines.\n",
      "[2022-11-22 18:19:53,963][INFO]: load_data() finished!\n",
      "[2022-11-22 18:19:54,132][INFO]: Processed 100.0% of log lines.\n",
      "[2022-11-22 18:19:54,237][INFO]: Output parse file\n",
      "[2022-11-22 18:19:54,249][INFO]: Output main file for append\n",
      "[2022-11-22 18:19:54,264][INFO]: lastestLindId: 1600\n",
      "[2022-11-22 18:19:54,295][INFO]: rootNodePath: output/spell/rootNode.pkl\n",
      "[2022-11-22 18:19:54,298][INFO]: logCluLPath: output/spell/logCluL.pkl\n",
      "[2022-11-22 18:19:54,299][INFO]: Store objects done.\n",
      "[2022-11-22 18:19:54,300][INFO]: Parsing done. [Time taken: 0:00:00.364100]\n",
      "Read 0M words\n",
      "Number of words:  75\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:    8756 lr:  0.000000 avg.loss:  4.135855 ETA:   0h 0m 0s\n",
      "[2022-11-22 18:19:55,165][INFO]: Parsing file: input/spell/bgl_2k_content.csv\n",
      "[2022-11-22 18:19:55,171][INFO]: Loaded 100.0% of log lines.\n",
      "[2022-11-22 18:19:55,174][INFO]: load_data() finished!\n",
      "[2022-11-22 18:19:55,212][INFO]: Processed 100.0% of log lines.\n",
      "[2022-11-22 18:19:55,240][INFO]: Output parse file\n",
      "[2022-11-22 18:19:55,249][INFO]: Output main file for append\n",
      "[2022-11-22 18:19:55,258][INFO]: lastestLindId: 400\n",
      "[2022-11-22 18:19:55,270][INFO]: rootNodePath: output/spell/rootNode.pkl\n",
      "[2022-11-22 18:19:55,274][INFO]: logCluLPath: output/spell/logCluL.pkl\n",
      "[2022-11-22 18:19:55,276][INFO]: Store objects done.\n",
      "[2022-11-22 18:19:55,277][INFO]: Parsing done. [Time taken: 0:00:00.112080]\n",
      "Read 0M words\n",
      "Number of words:  97\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:    8638 lr:  0.000000 avg.loss:  4.129039 ETA:   0h 0m 0s\n",
      "[2022-11-22 18:19:56,150][INFO]: Parsing file: input/spell/bgl_2k_content.csv\n",
      "[2022-11-22 18:19:56,172][INFO]: Loaded 100.0% of log lines.\n",
      "[2022-11-22 18:19:56,177][INFO]: load_data() finished!\n",
      "[2022-11-22 18:19:56,299][INFO]: Processed 100.0% of log lines.\n",
      "[2022-11-22 18:19:56,353][INFO]: Output parse file\n",
      "[2022-11-22 18:19:56,363][INFO]: Output main file for append\n",
      "[2022-11-22 18:19:56,376][INFO]: lastestLindId: 1600\n",
      "[2022-11-22 18:19:56,399][INFO]: rootNodePath: output/spell/rootNode.pkl\n",
      "[2022-11-22 18:19:56,401][INFO]: logCluLPath: output/spell/logCluL.pkl\n",
      "[2022-11-22 18:19:56,402][INFO]: Store objects done.\n",
      "[2022-11-22 18:19:56,403][INFO]: Parsing done. [Time taken: 0:00:00.252383]\n",
      "Read 0M words\n",
      "Number of words:  75\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:    8858 lr:  0.000000 avg.loss:  4.134029 ETA:   0h 0m 0s\n",
      "[2022-11-22 18:19:57,226][INFO]: Parsing file: input/spell/bgl_2k_content.csv\n",
      "[2022-11-22 18:19:57,231][INFO]: Loaded 100.0% of log lines.\n",
      "[2022-11-22 18:19:57,235][INFO]: load_data() finished!\n",
      "[2022-11-22 18:19:57,271][INFO]: Processed 100.0% of log lines.\n",
      "[2022-11-22 18:19:57,289][INFO]: Output parse file\n",
      "[2022-11-22 18:19:57,294][INFO]: Output main file for append\n",
      "[2022-11-22 18:19:57,301][INFO]: lastestLindId: 400\n",
      "[2022-11-22 18:19:57,313][INFO]: rootNodePath: output/spell/rootNode.pkl\n",
      "[2022-11-22 18:19:57,315][INFO]: logCluLPath: output/spell/logCluL.pkl\n",
      "[2022-11-22 18:19:57,316][INFO]: Store objects done.\n",
      "[2022-11-22 18:19:57,317][INFO]: Parsing done. [Time taken: 0:00:00.091477]\n",
      "[2022-11-22 18:19:57,330][INFO]: Parsing file: input/spell/bgl_2k_content.csv\n",
      "[2022-11-22 18:19:57,335][INFO]: Loaded 100.0% of log lines.\n",
      "[2022-11-22 18:19:57,337][INFO]: load_data() finished!\n",
      "[2022-11-22 18:19:57,370][INFO]: Processed 100.0% of log lines.\n",
      "[2022-11-22 18:19:57,388][INFO]: Output parse file\n",
      "[2022-11-22 18:19:57,394][INFO]: Output main file for append\n",
      "[2022-11-22 18:19:57,401][INFO]: lastestLindId: 400\n",
      "[2022-11-22 18:19:57,413][INFO]: rootNodePath: output/spell/rootNode.pkl\n",
      "[2022-11-22 18:19:57,415][INFO]: logCluLPath: output/spell/logCluL.pkl\n",
      "[2022-11-22 18:19:57,416][INFO]: Store objects done.\n",
      "[2022-11-22 18:19:57,417][INFO]: Parsing done. [Time taken: 0:00:00.086510]\n"
     ]
    }
   ],
   "source": [
    "drain_y_real = []\n",
    "drain_y_proba = []\n",
    "\n",
    "drain_precisions = []\n",
    "drain_recalls = []\n",
    "drain_avg_precisions = []\n",
    "\n",
    "drain_tprs = []\n",
    "drain_tprs2 = []\n",
    "drain_fprs = []\n",
    "drain_aucs = []\n",
    "drain_mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "drain_f1_scores = []\n",
    "drain_accuracy_scores = []\n",
    "drain_precision_scores = []\n",
    "drain_recall_scores = []\n",
    "\n",
    "drain_index = 0\n",
    "\n",
    "spell_y_real = []\n",
    "spell_y_proba = []\n",
    "\n",
    "spell_precisions = []\n",
    "spell_recalls = []\n",
    "spell_avg_precisions = []\n",
    "\n",
    "spell_tprs = []\n",
    "spell_tprs2 = []\n",
    "spell_fprs = []\n",
    "spell_aucs = []\n",
    "spell_mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "spell_f1_scores = []\n",
    "spell_accuracy_scores = []\n",
    "spell_precision_scores = []\n",
    "spell_recall_scores = []\n",
    "\n",
    "spell_index = 0\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=0)\n",
    "for train, test in cv.split(log_seqs, log_seq_anomaly_labels):\n",
    "    print(train.shape, test.shape)\n",
    "\n",
    "drain_pipe = Pipeline(steps=[('parsing', DrainParser()), ('word_embedding', WordEmbedding()), ('gnb', GaussianNB())])\n",
    "drain_pred_log_seq_anomaly_labels = drain_pipe.fit(log_seqs[train], log_seq_anomaly_labels[train]).predict(log_seqs[test])\n",
    "\n",
    "#spell_pipe = Pipeline(steps=[('parsing', SpellParser()), ('word_embedding', WordEmbedding()), ('gnb', GaussianNB())])\n",
    "#spell_pred_log_seq_anomaly_labels = spell_pipe.fit(log_seqs[train], log_seq_anomaly_labels[train]).predict(log_seqs[test])\n",
    "\n",
    "drain_probas_ = drain_pipe.fit(log_seqs[train], log_seq_anomaly_labels[train]).predict_proba(log_seqs[test])\n",
    "\n",
    "####### PR #######\n",
    "\n",
    "drain_precision, drain_recall, _ = precision_recall_curve(log_seq_anomaly_labels[test], drain_probas_[:, 1])\n",
    "drain_precisions.append(drain_precision)\n",
    "drain_recalls.append(drain_recall)\n",
    "\n",
    "drain_avg_precision = average_precision_score(log_seq_anomaly_labels[test], drain_probas_[:, 1])\n",
    "drain_avg_precisions.append(drain_avg_precision)\n",
    "\n",
    "np.append(drain_y_real, log_seq_anomaly_labels[test])\n",
    "np.append(drain_y_proba, drain_probas_[:, 1])\n",
    "\n",
    "####### ROC #######\n",
    "\n",
    "drain_fpr, drain_tpr, _ = roc_curve(log_seq_anomaly_labels[test], drain_probas_[:, 1])\n",
    "drain_tprs.append(np.interp(drain_mean_fpr, drain_fpr, drain_tpr))\n",
    "drain_tprs2.append(drain_tpr)\n",
    "drain_fprs.append(drain_fpr)\n",
    "\n",
    "drain_tprs[-1][0] = 0.0\n",
    "roc_auc = auc(drain_fpr, drain_tpr)\n",
    "drain_aucs.append(roc_auc)\n",
    "\n",
    "####### F1-score, Accuracy, Precision and Recall #######\n",
    "\n",
    "drain_y_pred = drain_pipe.predict(log_seqs[test])\n",
    "\n",
    "drain_f1_scores.append(f1_score(log_seq_anomaly_labels[test], drain_y_pred))\n",
    "drain_accuracy_scores.append(accuracy_score(log_seq_anomaly_labels[test], drain_y_pred))\n",
    "drain_precision_scores.append(precision_score(log_seq_anomaly_labels[test], drain_y_pred))\n",
    "drain_recall_scores.append(recall_score(log_seq_anomaly_labels[test], drain_y_pred))\n",
    "\n",
    "drain_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23529411764705885]\n",
      "[0.7200000000000001]\n",
      "[0.8375]\n",
      "[0.9125]\n",
      "[0.3333333333333333]\n",
      "[0.6428571428571429]\n",
      "[0.18181818181818182]\n",
      "[0.8181818181818182]\n"
     ]
    }
   ],
   "source": [
    "print('F1 Scores')\n",
    "print('\\n')\n",
    "print('Spell: ', spell_f1_scores)\n",
    "print('\\n')\n",
    "print('Drain: ',drain_f1_scores)\n",
    "print('\\n')\n",
    "print('Average Scores')\n",
    "print('Spell: ', np.average(spell_f1_scores), ' Drain: ', np.average(drain_f1_scores))\n",
    "\n",
    "print('\\n')\n",
    "print('Accuracy Scores')\n",
    "print('\\n')\n",
    "print('Spell: ', spell_accuracy_scores)\n",
    "print('\\n')\n",
    "print('Drain: ', drain_accuracy_scores)\n",
    "print('\\n')\n",
    "print('Average Scores')\n",
    "print('Spell: ', np.average(spell_accuracy_scores), ' Drain: ', np.average(drain_accuracy_scores))\n",
    "\n",
    "print('\\n')\n",
    "print('Precision Scores')\n",
    "print('\\n')\n",
    "print('Spell: ', spell_precision_scores)\n",
    "print('\\n')\n",
    "print('Drain: ', drain_precision_scores)\n",
    "print('\\n')\n",
    "print('Spell: ', np.average(spell_precision_scores), ' Drain: ', np.average(drain_precision_scores))\n",
    "\n",
    "print('\\n')\n",
    "print('Recall Scores')\n",
    "print('\\n')\n",
    "print('Spell: ', spell_recall_scores)\n",
    "print('\\n')\n",
    "print('Drain: ', drain_recall_scores)\n",
    "print('\\n')\n",
    "print('Spell: ', np.average(spell_recall_scores), ' Drain: ', np.average(drain_recall_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0]\n",
      "[0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0]\n",
      "[[64  5]\n",
      " [ 2  9]]\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1]\n",
      "[[65  4]\n",
      " [ 9  2]]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print('F1 Scores')\n",
    "print('\\n')\n",
    "print('Spell: ', spell_f1_scores)\n",
    "print('\\n')\n",
    "print('Drain: ',drain_f1_scores)\n",
    "print('\\n')\n",
    "print('Average Scores')\n",
    "print('Spell: ', np.average(spell_f1_scores), ' Drain: ', np.average(drain_f1_scores))\n",
    "\n",
    "print('\\n')\n",
    "print('Accuracy Scores')\n",
    "print('\\n')\n",
    "print('Spell: ', spell_accuracy_scores)\n",
    "print('\\n')\n",
    "print('Drain: ', drain_accuracy_scores)\n",
    "print('\\n')\n",
    "print('Average Scores')\n",
    "print('Spell: ', np.average(spell_accuracy_scores), ' Drain: ', np.average(drain_accuracy_scores))\n",
    "\n",
    "print('\\n')\n",
    "print('Precision Scores')\n",
    "print('\\n')\n",
    "print('Spell: ', spell_precision_scores)\n",
    "print('\\n')\n",
    "print('Drain: ', drain_precision_scores)\n",
    "print('\\n')\n",
    "print('Spell: ', np.average(spell_precision_scores), ' Drain: ', np.average(drain_precision_scores))\n",
    "\n",
    "print('\\n')\n",
    "print('Recall Scores')\n",
    "print('\\n')\n",
    "print('Spell: ', spell_recall_scores)\n",
    "print('\\n')\n",
    "print('Drain: ', drain_recall_scores)\n",
    "print('\\n')\n",
    "print('Spell: ', np.average(spell_recall_scores), ' Drain: ', np.average(drain_recall_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('ms-ds13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7d5d95ec871826f4c96f39204edc263930b1065d3d6b0d23c0891d0cf865f41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
