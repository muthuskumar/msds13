{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "import glob\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from csv import (writer, DictWriter)\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from drain3 import TemplateMiner\n",
    "from drain3.template_miner_config import TemplateMinerConfig\n",
    "\n",
    "from spellpy import spell\n",
    "\n",
    "import fasttext\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import (auc, roc_curve, average_precision_score, precision_recall_curve, f1_score, accuracy_score,\n",
    "                            recall_score, precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = os.getcwd()\n",
    "\n",
    "input_dir = 'input'\n",
    "output_dir = 'output'\n",
    "\n",
    "spell_input_dir = 'input/spell'\n",
    "spell_output_dir = 'output/spell'\n",
    "\n",
    "drain_input_dir = 'input/drain'\n",
    "drain_output_dir = 'output/drain'\n",
    "\n",
    "if not path.abspath(path.join(project_root, spell_input_dir)):\n",
    "    os.makedirs(path.abspath(path.join(project_root, spell_input_dir)))\n",
    "\n",
    "if not path.abspath(path.join(project_root, spell_output_dir)):\n",
    "    os.makedirs(path.abspath(path.join(project_root, spell_output_dir)))\n",
    "\n",
    "if not path.abspath(path.join(project_root, drain_input_dir)):\n",
    "    os.makedirs(path.abspath(path.join(project_root, drain_input_dir)))\n",
    "\n",
    "if not path.abspath(path.join(project_root, drain_output_dir)):\n",
    "    os.makedirs(path.abspath(path.join(project_root, drain_output_dir)))\n",
    "\n",
    "config_dir = 'config'\n",
    "bucket_name = 'sagemaker-studio-326787221562-jycpwz9gs3f'\n",
    "log_file_key = 'BGL_20050610.csv'\n",
    "pickle_key = 'AllOutput-' + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\") + '.pkl'\n",
    "    \n",
    "WINDOW_SIZE = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert BGL.log file to CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "s3_client = boto3.client('s3')\n",
    "log_file = s3_client.get_object(Bucket = bucket_name, Key = log_file_key)\n",
    "log_csv_file = log_file['Body']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3672280, 13)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3672280 entries, 0 to 3672279\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Dtype \n",
      "---  ------             ----- \n",
      " 0   Unnamed: 0         int64 \n",
      " 1   Anomaly Type       object\n",
      " 2   Timestamp (ms)     int64 \n",
      " 3   Date               object\n",
      " 4   Node               object\n",
      " 5   Timestamp          object\n",
      " 6   Node Repeat        object\n",
      " 7   Message Type       object\n",
      " 8   Component          object\n",
      " 9   Level              object\n",
      " 10  Content            object\n",
      " 11  Anomaly Label      int64 \n",
      " 12  Non-Anomaly Label  int64 \n",
      "dtypes: int64(4), object(9)\n",
      "memory usage: 364.2+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Anomaly Type</th>\n",
       "      <th>Timestamp (ms)</th>\n",
       "      <th>Date</th>\n",
       "      <th>Node</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Node Repeat</th>\n",
       "      <th>Message Type</th>\n",
       "      <th>Component</th>\n",
       "      <th>Level</th>\n",
       "      <th>Content</th>\n",
       "      <th>Anomaly Label</th>\n",
       "      <th>Non-Anomaly Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838570</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:42:50.363779</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838570</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:42:50.527847</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838570</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:42:50.675872</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838570</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:42:50.823719</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838570</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:42:50.982731</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838571</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:42:51.131467</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838571</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:42:51.293532</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838571</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:42:51.428563</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838571</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:42:51.601412</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838571</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:42:51.749199</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838571</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:42:51.885834</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838572</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:42:52.041388</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838572</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:42:52.199063</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838572</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:42:52.345821</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838572</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:42:52.493353</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838572</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:42:52.638135</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838572</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:42:52.807927</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838572</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:42:52.951717</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838573</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:42:53.125780</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>-</td>\n",
       "      <td>1117838573</td>\n",
       "      <td>2005.06.03</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>2005-06-03 15:42:53.276129</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>RAS</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>INFO</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 Anomaly Type  Timestamp (ms)        Date                 Node  \\\n",
       "0            0            -      1117838570  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "1            1            -      1117838570  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "2            2            -      1117838570  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "3            3            -      1117838570  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "4            4            -      1117838570  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "5            5            -      1117838571  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "6            6            -      1117838571  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "7            7            -      1117838571  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "8            8            -      1117838571  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "9            9            -      1117838571  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "10          10            -      1117838571  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "11          11            -      1117838572  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "12          12            -      1117838572  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "13          13            -      1117838572  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "14          14            -      1117838572  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "15          15            -      1117838572  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "16          16            -      1117838572  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "17          17            -      1117838572  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "18          18            -      1117838573  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "19          19            -      1117838573  2005.06.03  R02-M1-N0-C:J12-U11   \n",
       "\n",
       "                     Timestamp          Node Repeat Message Type Component  \\\n",
       "0   2005-06-03 15:42:50.363779  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "1   2005-06-03 15:42:50.527847  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "2   2005-06-03 15:42:50.675872  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "3   2005-06-03 15:42:50.823719  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "4   2005-06-03 15:42:50.982731  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "5   2005-06-03 15:42:51.131467  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "6   2005-06-03 15:42:51.293532  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "7   2005-06-03 15:42:51.428563  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "8   2005-06-03 15:42:51.601412  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "9   2005-06-03 15:42:51.749199  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "10  2005-06-03 15:42:51.885834  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "11  2005-06-03 15:42:52.041388  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "12  2005-06-03 15:42:52.199063  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "13  2005-06-03 15:42:52.345821  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "14  2005-06-03 15:42:52.493353  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "15  2005-06-03 15:42:52.638135  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "16  2005-06-03 15:42:52.807927  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "17  2005-06-03 15:42:52.951717  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "18  2005-06-03 15:42:53.125780  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "19  2005-06-03 15:42:53.276129  R02-M1-N0-C:J12-U11          RAS    KERNEL   \n",
       "\n",
       "   Level                                   Content  Anomaly Label  \\\n",
       "0   INFO  instruction cache parity error corrected              0   \n",
       "1   INFO  instruction cache parity error corrected              0   \n",
       "2   INFO  instruction cache parity error corrected              0   \n",
       "3   INFO  instruction cache parity error corrected              0   \n",
       "4   INFO  instruction cache parity error corrected              0   \n",
       "5   INFO  instruction cache parity error corrected              0   \n",
       "6   INFO  instruction cache parity error corrected              0   \n",
       "7   INFO  instruction cache parity error corrected              0   \n",
       "8   INFO  instruction cache parity error corrected              0   \n",
       "9   INFO  instruction cache parity error corrected              0   \n",
       "10  INFO  instruction cache parity error corrected              0   \n",
       "11  INFO  instruction cache parity error corrected              0   \n",
       "12  INFO  instruction cache parity error corrected              0   \n",
       "13  INFO  instruction cache parity error corrected              0   \n",
       "14  INFO  instruction cache parity error corrected              0   \n",
       "15  INFO  instruction cache parity error corrected              0   \n",
       "16  INFO  instruction cache parity error corrected              0   \n",
       "17  INFO  instruction cache parity error corrected              0   \n",
       "18  INFO  instruction cache parity error corrected              0   \n",
       "19  INFO  instruction cache parity error corrected              0   \n",
       "\n",
       "    Non-Anomaly Label  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   1  \n",
       "5                   1  \n",
       "6                   1  \n",
       "7                   1  \n",
       "8                   1  \n",
       "9                   1  \n",
       "10                  1  \n",
       "11                  1  \n",
       "12                  1  \n",
       "13                  1  \n",
       "14                  1  \n",
       "15                  1  \n",
       "16                  1  \n",
       "17                  1  \n",
       "18                  1  \n",
       "19                  1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = pd.read_csv(log_csv_file)\n",
    "print(original_df.shape)\n",
    "print(original_df.info())\n",
    "original_df.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anomaly Label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Anomaly Label                                   Content\n",
       "0               0  instruction cache parity error corrected\n",
       "1               0  instruction cache parity error corrected\n",
       "2               0  instruction cache parity error corrected\n",
       "3               0  instruction cache parity error corrected\n",
       "4               0  instruction cache parity error corrected\n",
       "5               0  instruction cache parity error corrected\n",
       "6               0  instruction cache parity error corrected\n",
       "7               0  instruction cache parity error corrected\n",
       "8               0  instruction cache parity error corrected\n",
       "9               0  instruction cache parity error corrected\n",
       "10              0  instruction cache parity error corrected\n",
       "11              0  instruction cache parity error corrected\n",
       "12              0  instruction cache parity error corrected\n",
       "13              0  instruction cache parity error corrected\n",
       "14              0  instruction cache parity error corrected\n",
       "15              0  instruction cache parity error corrected\n",
       "16              0  instruction cache parity error corrected\n",
       "17              0  instruction cache parity error corrected\n",
       "18              0  instruction cache parity error corrected\n",
       "19              0  instruction cache parity error corrected"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = original_df[['Anomaly Label', 'Content']]\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Log Sequences and Labels for Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = math.floor(df['Content'].index.size/WINDOW_SIZE)\n",
    "r = math.floor(df['Content'].index.size%WINDOW_SIZE)\n",
    "\n",
    "if r != 0:\n",
    "    log_seqs = np.array(np.split(np.array(df['Content'])[:-r], n))\n",
    "else:\n",
    "    log_seqs = np.array(np.split(np.array(df['Content']), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if r != 0:\n",
    "    log_seq_idx = np.array(np.split(df.index.to_numpy()[:-r], n))\n",
    "else:\n",
    "    log_seq_idx = np.array(np.split(df.index.to_numpy(), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_seq_anomaly_labels = np.empty([n], dtype=int)\n",
    "i = 0\n",
    "for seq in log_seq_idx:\n",
    "    if np.sum(df.loc[seq]['Anomaly Label'].values) > 0:\n",
    "        log_seq_anomaly_labels[i] = 1\n",
    "    else:\n",
    "        log_seq_anomaly_labels[i] = 0\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Parsing & Numericalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drain Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(drain_input_dir + '/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "files = glob.glob(drain_output_dir + '/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "drain_config_file = path.abspath(path.join(project_root, config_dir, 'drain3.ini'))\n",
    "\n",
    "main_structured_csv_filename = 'BGL_main_structured.csv'\n",
    "drain_main_structured_csv_file = path.abspath(path.join(project_root, drain_output_dir, main_structured_csv_filename))\n",
    "\n",
    "templates_csv_filename = 'BGL_main_templates.csv'\n",
    "drain_templates_csv_file = path.abspath(path.join(project_root, drain_output_dir, templates_csv_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrainParser(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        config = TemplateMinerConfig()\n",
    "        config.load(drain_config_file)\n",
    "\n",
    "        self.template_miner = TemplateMiner(config=config)\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, log_seqs, y = None):\n",
    "        log_seqs_list = log_seqs.reshape([-1]).tolist()\n",
    "        self.parsed = []\n",
    "\n",
    "        for line in log_seqs_list:\n",
    "            self.parsed.append(self.template_miner.add_log_message(line))\n",
    "\n",
    "        # Uncomment during debug to view the parser output\n",
    "        # self.write_output_to_csv()\n",
    "\n",
    "        template_seq = [x['cluster_id']-1 for x in self.parsed]\n",
    "        n = math.floor(len(template_seq)/WINDOW_SIZE)\n",
    "        template_seqs = np.array(np.split(np.array(template_seq), n))\n",
    "\n",
    "        return template_seqs\n",
    "    \n",
    "    def cluster_template_to_tuple(self, cluster):\n",
    "        return (cluster.cluster_id, cluster.get_template(), cluster.size,)\n",
    "\n",
    "    def write_output_to_csv(self):\n",
    "        with open(drain_main_structured_csv_file, 'w') as drain_main_structured_csv_file_obj:\n",
    "            main_structured_csv_filewriter = DictWriter(drain_main_structured_csv_file_obj, fieldnames=['template_mined', 'cluster_id', 'change_type', 'cluster_size', 'cluster_count'])\n",
    "            main_structured_csv_filewriter.writeheader()\n",
    "            for line in self.parsed:\n",
    "                main_structured_csv_filewriter.writerow(line)\n",
    "            drain_main_structured_csv_file_obj.close\n",
    "            \n",
    "        clusters = self.template_miner.drain.clusters\n",
    "\n",
    "        with open(drain_templates_csv_file, 'a') as drain_templates_csv_file_obj:\n",
    "            drain_templates_csv_filewriter = writer(drain_templates_csv_file_obj)\n",
    "            drain_templates_csv_filewriter.writerow(header for header in ['cluster_id', 'template', 'size'])\n",
    "            for line in clusters:\n",
    "                drain_templates_csv_filewriter.writerow(self.cluster_template_to_tuple(line))\n",
    "            drain_templates_csv_file_obj.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spell Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_content_csv_file_name = 'bgl_2k_content.csv'\n",
    "log_content_csv_file = log_file = path.abspath(path.join(project_root, spell_input_dir, log_content_csv_file_name))\n",
    "\n",
    "main_structured_csv_filename = 'BGL_main_structured.csv'\n",
    "spell_main_structured_csv_file = path.abspath(path.join(project_root, spell_output_dir, main_structured_csv_filename))\n",
    "\n",
    "templates_csv_filename = 'BGL_main_templates.csv'\n",
    "spell_templates_csv_file = path.abspath(path.join(project_root, spell_output_dir, templates_csv_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpellParser(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        log_format = '<Content>'\n",
    "        tau = 0.5\n",
    "\n",
    "        self.parser = spell.LogParser(indir=spell_input_dir, outdir=spell_output_dir,\n",
    "                             log_format=log_format, tau=tau, logmain='BGL')\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, log_seqs, y = None):\n",
    "        log_seqs_list = log_seqs.reshape([-1]).tolist()\n",
    "\n",
    "        ldf = pd.DataFrame(log_seqs_list, columns=['Content'])\n",
    "        ldf.to_csv(log_content_csv_file, index=False, header=False)\n",
    "\n",
    "        self.parser.parse(log_content_csv_file_name)\n",
    "\n",
    "        nums = self.numericalize()\n",
    "        n = math.floor(len(nums)/WINDOW_SIZE)\n",
    "        nums = np.array(np.split(nums, n))\n",
    "        \n",
    "        # Comment during debug to view parser output\n",
    "        self.cleanup_files()\n",
    "        \n",
    "        return nums\n",
    "\n",
    "    def numericalize(self):\n",
    "        output_df = pd.read_csv(spell_main_structured_csv_file)\n",
    "\n",
    "        return output_df['EventId'].to_numpy()\n",
    "\n",
    "    def cleanup_files(self):\n",
    "        files = glob.glob(spell_input_dir + '/*')\n",
    "        for f in files:\n",
    "            os.remove(f)\n",
    "\n",
    "        files = glob.glob(spell_output_dir + '/*')\n",
    "        for f in files:\n",
    "            os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbedding(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.NUMBER_OF_DIMENSIONS = 100\n",
    "\n",
    "    def fit(self, template_seqs, y = None):\n",
    "        template_seqs_filename = 'bgl_train_seqs.txt'\n",
    "        template_seqs_file = path.abspath(path.join(project_root, output_dir, template_seqs_filename))\n",
    "        np.savetxt(template_seqs_file, template_seqs, fmt='%s')\n",
    "        self.fasttext_model = fasttext.train_unsupervised(template_seqs_file, model='cbow', minCount=1, dim=self.NUMBER_OF_DIMENSIONS)\n",
    "        \n",
    "        # Comment during debug to view embedding input\n",
    "        os.remove(template_seqs_file)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, template_seqs, y = None):\n",
    "        template_seqs_ = template_seqs.copy()\n",
    "        template_seqs_ = np.apply_along_axis(self.average_embeddings, 1, template_seqs)\n",
    "\n",
    "        return template_seqs_\n",
    "\n",
    "    def average_embeddings(self, num_lse_vector):\n",
    "        s2v_vector = self.fasttext_model.get_sentence_vector(' '.join(np.vectorize(str)(num_lse_vector)))\n",
    "        return s2v_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drain_y_real = []\n",
    "drain_y_proba = []\n",
    "\n",
    "drain_precisions = []\n",
    "drain_avg_precisions = []\n",
    "\n",
    "drain_tprs = []\n",
    "drain_tprs2 = []\n",
    "drain_fprs = []\n",
    "drain_aucs = []\n",
    "drain_mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "drain_f1_scores = []\n",
    "drain_accuracy_scores = []\n",
    "drain_precision_scores = []\n",
    "drain_recall_scores = []\n",
    "\n",
    "drain_index = 0\n",
    "\n",
    "spell_y_real = []\n",
    "spell_y_proba = []\n",
    "\n",
    "spell_precisions = []\n",
    "spell_recalls = []\n",
    "spell_avg_precisions = []\n",
    "\n",
    "spell_tprs = []\n",
    "spell_tprs2 = []\n",
    "spell_fprs = []\n",
    "spell_aucs = []\n",
    "spell_mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "spell_f1_scores = []\n",
    "spell_accuracy_scores = []\n",
    "spell_precision_scores = []\n",
    "spell_recall_scores = []\n",
    "\n",
    "spell_index = 0\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=2, random_state=0)\n",
    "for train, test in cv.split(log_seqs, log_seq_anomaly_labels):\n",
    "    print(train.shape, test.shape)\n",
    "\n",
    "    drain_pipe = Pipeline(steps=[('parsing', DrainParser()), ('word_embedding', WordEmbedding()), ('gnb', GaussianNB())])\n",
    "    #drain_pipe = Pipeline(steps=[('parsing', DrainParser()), ('word_embedding', WordEmbedding()), ('random_forest', RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1))])\n",
    "    drain_probas_ = drain_pipe.fit(log_seqs[train], log_seq_anomaly_labels[train]).predict_proba(log_seqs[test])\n",
    "    drain_y_pred = drain_pipe.predict(log_seqs[test])\n",
    "\n",
    "    spell_pipe = Pipeline(steps=[('parsing', SpellParser()), ('word_embedding', WordEmbedding()), ('gnb', GaussianNB())])\n",
    "    #spell_pipe = Pipeline(steps=[('parsing', SpellParser()), ('word_embedding', WordEmbedding()), ('random_forest', RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1))])\n",
    "    spell_probas_ = spell_pipe.fit(log_seqs[train], log_seq_anomaly_labels[train]).predict_proba(log_seqs[test])\n",
    "    spell_y_pred = spell_pipe.predict(log_seqs[test])\n",
    "\n",
    "    ####### PR #######\n",
    "\n",
    "    drain_precision, drain_recall, _ = precision_recall_curve(log_seq_anomaly_labels[test], drain_probas_[:, 1])\n",
    "    drain_precisions.append(drain_precision)\n",
    "    drain_recalls.append(drain_recall)\n",
    "\n",
    "    drain_avg_precision = average_precision_score(log_seq_anomaly_labels[test], drain_probas_[:, 1])\n",
    "    drain_avg_precisions.append(drain_avg_precision)\n",
    "        \n",
    "    drain_y_real.append(log_seq_anomaly_labels[test])\n",
    "    drain_y_proba.append(drain_probas_[:, 1])\n",
    "\n",
    "    ####### ROC #######\n",
    "\n",
    "    drain_fpr, drain_tpr, _ = roc_curve(log_seq_anomaly_labels[test], drain_probas_[:, 1])\n",
    "    drain_tprs.append(np.interp(drain_mean_fpr, drain_fpr, drain_tpr))\n",
    "    drain_tprs2.append(drain_tpr)\n",
    "    drain_fprs.append(drain_fpr)\n",
    "        \n",
    "    drain_tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(drain_fpr, drain_tpr)\n",
    "    drain_aucs.append(roc_auc)\n",
    "\n",
    "    ####### F1-score, Accuracy, Precision and Recall #######\n",
    "\n",
    "    drain_f1_scores.append(f1_score(log_seq_anomaly_labels[test], drain_y_pred))\n",
    "    drain_accuracy_scores.append(accuracy_score(log_seq_anomaly_labels[test], drain_y_pred))\n",
    "    drain_precision_scores.append(precision_score(log_seq_anomaly_labels[test], drain_y_pred))\n",
    "    drain_recall_scores.append(recall_score(log_seq_anomaly_labels[test], drain_y_pred))\n",
    "\n",
    "    drain_index += 1\n",
    "\n",
    "    \n",
    "\n",
    "    ####### PR #######\n",
    "\n",
    "    spell_precision, spell_recall, _ = precision_recall_curve(log_seq_anomaly_labels[test], spell_probas_[:, 1])\n",
    "    spell_precisions.append(spell_precision)\n",
    "    spell_recalls.append(spell_recall)\n",
    "\n",
    "    spell_avg_precision = average_precision_score(log_seq_anomaly_labels[test], spell_probas_[:, 1])\n",
    "    spell_avg_precisions.append(spell_avg_precision)\n",
    "        \n",
    "    spell_y_real.append(log_seq_anomaly_labels[test])\n",
    "    spell_y_proba.append(spell_probas_[:, 1])\n",
    "\n",
    "    ####### ROC #######\n",
    "\n",
    "    spell_fpr, spell_tpr, _ = roc_curve(log_seq_anomaly_labels[test], spell_probas_[:, 1])\n",
    "    spell_tprs.append(np.interp(spell_mean_fpr, spell_fpr, spell_tpr))\n",
    "    spell_tprs2.append(spell_tpr)\n",
    "    spell_fprs.append(spell_fpr)\n",
    "        \n",
    "    spell_tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(spell_fpr, spell_tpr)\n",
    "    spell_aucs.append(roc_auc)\n",
    "\n",
    "    ####### F1-score, Accuracy, Precision and Recall #######\n",
    "\n",
    "    spell_f1_scores.append(f1_score(log_seq_anomaly_labels[test], spell_y_pred))\n",
    "    spell_accuracy_scores.append(accuracy_score(log_seq_anomaly_labels[test], spell_y_pred))\n",
    "    spell_precision_scores.append(precision_score(log_seq_anomaly_labels[test], spell_y_pred))\n",
    "    spell_recall_scores.append(recall_score(log_seq_anomaly_labels[test], spell_y_pred))\n",
    "\n",
    "    spell_index += 1\n",
    "\n",
    "drain_y_real = np.concatenate(drain_y_real)\n",
    "drain_y_proba = np.concatenate(drain_y_proba)\n",
    "\n",
    "spell_y_real = np.concatenate(spell_y_real)\n",
    "spell_y_proba = np.concatenate(spell_y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 Scores')\n",
    "print('Spell: ', spell_f1_scores)\n",
    "print('Drain: ',drain_f1_scores)\n",
    "print('Average Scores - ', 'Spell: ', np.average(spell_f1_scores), ' Drain: ', np.average(drain_f1_scores))\n",
    "print('\\n')\n",
    "\n",
    "print('Accuracy Scores')\n",
    "print('Spell: ', spell_accuracy_scores)\n",
    "print('Drain: ', drain_accuracy_scores)\n",
    "print('Average Scores - ', 'Spell: ', np.average(spell_accuracy_scores), ' Drain: ', np.average(drain_accuracy_scores))\n",
    "print('\\n')\n",
    "\n",
    "print('Precision Scores')\n",
    "print('Spell: ', spell_precision_scores)\n",
    "print('Drain: ', drain_precision_scores)\n",
    "print('Average Scores - ', 'Spell: ', np.average(spell_precision_scores), ' Drain: ', np.average(drain_precision_scores))\n",
    "print('\\n')\n",
    "\n",
    "print('Recall Scores')\n",
    "print('Spell: ', spell_recall_scores)\n",
    "print('Drain: ', drain_recall_scores)\n",
    "print('Average Scores - ', 'Spell: ', np.average(spell_recall_scores), ' Drain: ', np.average(drain_recall_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_output = {\n",
    "    \"y_real\": {\"spell\": spell_y_real, \"drain\": drain_y_real},\n",
    "    \"y_pred\": {\"spell\": spell_y_pred, \"drain\": drain_y_pred},\n",
    "    \"y_proba\": {\"spell\": spell_y_proba, \"drain\": drain_y_proba},\n",
    "    \"accuracy\": {\"spell\": spell_accuracy_scores, \"drain\": drain_accuracy_scores},\n",
    "    \"precision\": {\"spell\": spell_precision_scores, \"drain\": drain_precision_scores},\n",
    "    \"recall\": {\"spell\": spell_recall_scores, \"drain\": drain_recall_scores},\n",
    "    \"f1_score\": {\"spell\": spell_f1_scores, \"drain\": drain_f1_scores},\n",
    "    \"tprs\": {\"spell\": spell_tprs, \"drain\": drain_tprs},\n",
    "    \"tprs2\": {\"spell\": spell_tprs2, \"drain\": drain_tprs2},\n",
    "    \"fprs\": {\"spell\": spell_fprs, \"drain\": drain_fprs},\n",
    "    \"aucs\": {\"spell\": spell_aucs, \"drain\": drain_aucs},\n",
    "    \"mean_fpr\": {\"spell\": spell_mean_fpr, \"drain\": drain_mean_fpr},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_byte_obj = pickle.dumps(all_output)\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\")\n",
    "s3_resource.Object(bucket_name, pickle_key).put(Body=pickle_byte_obj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b7d5d95ec871826f4c96f39204edc263930b1065d3d6b0d23c0891d0cf865f41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
